{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "166435ef9e54740c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Install pyterrier it using pip (`pip install python-terrier`).\n",
    "\n",
    "### Step 1: Initialize PyTerrier\n",
    "\n",
    "First, you need to initialize PyTerrier. This is typically done once per notebook or script.\n",
    "\n",
    "```python\n",
    "import pyterrier as pt\n",
    "if not pt.started():\n",
    "    pt.init()\n",
    "```\n",
    "\n",
    "### Step 2: Dataset Loading\n",
    "\n",
    "Load your dataset. You can use one of the datasets available in PyTerrier, or load your own dataset.\n",
    "\n",
    "```python\n",
    "# Example of loading a dataset from PyTerrier\n",
    "dataset = pt.get_dataset('irds:your-dataset-name')\n",
    "# For custom datasets, you'd typically load them into a dataframe or similar structure\n",
    "```\n",
    "\n",
    "### Step 3: Preprocessing and Query Rewriting\n",
    "\n",
    "Implement the NLP-based query understanding and rewriting. You might use existing NLP libraries such as spaCy or Hugging Face's Transformers for this purpose.\n",
    "\n",
    "```python\n",
    "from your_query_rewriting_module import rewrite_query\n",
    "\n",
    "# This is a placeholder function. You will implement your query understanding and rewriting logic here.\n",
    "def preprocess_query(query):\n",
    "    # Use NLP techniques to understand and rewrite the query\n",
    "    rewritten_query = rewrite_query(query)\n",
    "    return rewritten_query\n",
    "```\n",
    "\n",
    "### Step 4: Developing the IR System\n",
    "\n",
    "Develop your prototype IR system. This involves setting up the indexing and retrieval process.\n",
    "\n",
    "```python\n",
    "# Indexing\n",
    "indexer = pt.DFIndexer(\"./index_path\", overwrite=True)\n",
    "index_ref = indexer.index(dataset.get_corpus_iter())\n",
    "\n",
    "# Retrieval\n",
    "# You can use one of PyTerrier's built-in retrieval models or develop your own.\n",
    "retriever = pt.BatchRetrieve(index_ref, wmodel=\"BM25\")\n",
    "```\n",
    "\n",
    "### Step 5: Experimentation\n",
    "\n",
    "Run experiments using your IR system. This includes query processing, retrieval, and evaluation against your benchmarks.\n",
    "\n",
    "```python\n",
    "from pyterrier.measures import RR, nDCG\n",
    "\n",
    "# Example query processing and retrieval\n",
    "def run_query_and_evaluate(query):\n",
    "    rewritten_query = preprocess_query(query)\n",
    "    result = retriever.transform(rewritten_query)\n",
    "    # Evaluation - assuming you have a test set with relevance judgments\n",
    "    eval_result = pt.Utils.evaluate(result, qrels, measures=[RR, nDCG])\n",
    "    return eval_result\n",
    "\n",
    "# Example usage\n",
    "query = \"Your test query\"\n",
    "evaluation_metrics = run_query_and_evaluate(query)\n",
    "print(evaluation_metrics)\n",
    "```\n",
    "\n",
    "### Step 6: Analysis\n",
    "\n",
    "Analyze the results to evaluate the effectiveness of your advanced query understanding and rewriting techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Project Setup and Data Preparation\n",
    "\n",
    "## Install PyTerrier\n",
    "\n",
    "Imports the PyTerrier library and initializes it. This step is necessary to use PyTerrier's functionalities.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5a1f7e502a977965"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-terrier in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (0.10.0)\r\n",
      "Requirement already satisfied: numpy in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (1.26.4)\r\n",
      "Requirement already satisfied: pandas in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (2.2.0)\r\n",
      "Requirement already satisfied: wget in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (3.2)\r\n",
      "Requirement already satisfied: tqdm in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (4.65.0)\r\n",
      "Requirement already satisfied: pyjnius>=1.4.2 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (1.6.1)\r\n",
      "Requirement already satisfied: matchpy in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (0.5.5)\r\n",
      "Requirement already satisfied: scikit-learn in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (1.4.0)\r\n",
      "Requirement already satisfied: deprecated in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (1.2.14)\r\n",
      "Requirement already satisfied: chest in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (0.2.3)\r\n",
      "Requirement already satisfied: scipy in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (1.12.0)\r\n",
      "Requirement already satisfied: requests in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (2.31.0)\r\n",
      "Requirement already satisfied: joblib in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (1.3.2)\r\n",
      "Requirement already satisfied: nptyping==1.4.4 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (1.4.4)\r\n",
      "Requirement already satisfied: more-itertools in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (10.2.0)\r\n",
      "Requirement already satisfied: ir-datasets>=0.3.2 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (0.5.6)\r\n",
      "Requirement already satisfied: jinja2 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (3.1.3)\r\n",
      "Requirement already satisfied: statsmodels in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (0.14.1)\r\n",
      "Requirement already satisfied: ir-measures>=0.3.1 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (0.3.3)\r\n",
      "Requirement already satisfied: dill in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (0.3.8)\r\n",
      "Requirement already satisfied: pytrec-eval-terrier>=0.5.3 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (0.5.6)\r\n",
      "Requirement already satisfied: typish>=1.7.0 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from nptyping==1.4.4->python-terrier) (1.9.3)\r\n",
      "Requirement already satisfied: beautifulsoup4>=4.4.1 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier) (4.12.2)\r\n",
      "Requirement already satisfied: inscriptis>=2.2.0 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier) (2.4.0.1)\r\n",
      "Requirement already satisfied: lxml>=4.5.2 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier) (5.1.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier) (6.0.1)\r\n",
      "Requirement already satisfied: trec-car-tools>=2.5.4 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier) (2.6)\r\n",
      "Requirement already satisfied: lz4>=3.1.10 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier) (4.3.3)\r\n",
      "Requirement already satisfied: warc3-wet>=0.2.3 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier) (0.2.3)\r\n",
      "Requirement already satisfied: warc3-wet-clueweb09>=0.2.5 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier) (0.2.5)\r\n",
      "Requirement already satisfied: zlib-state>=0.1.3 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier) (0.1.6)\r\n",
      "Requirement already satisfied: ijson>=3.1.3 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier) (3.2.3)\r\n",
      "Requirement already satisfied: pyautocorpus>=0.1.1 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier) (0.1.12)\r\n",
      "Requirement already satisfied: unlzw3>=0.2.1 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier) (0.2.2)\r\n",
      "Requirement already satisfied: cwl-eval>=1.0.10 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from ir-measures>=0.3.1->python-terrier) (1.0.12)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from requests->python-terrier) (2.0.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from requests->python-terrier) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from requests->python-terrier) (2.1.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from requests->python-terrier) (2024.2.2)\r\n",
      "Requirement already satisfied: heapdict in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from chest->python-terrier) (1.0.1)\r\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from deprecated->python-terrier) (1.16.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from jinja2->python-terrier) (2.1.3)\r\n",
      "Requirement already satisfied: multiset<3.0,>=2.0 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from matchpy->python-terrier) (2.1.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from pandas->python-terrier) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from pandas->python-terrier) (2023.3.post1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from pandas->python-terrier) (2024.1)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from scikit-learn->python-terrier) (3.3.0)\r\n",
      "Requirement already satisfied: patsy>=0.5.4 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from statsmodels->python-terrier) (0.5.6)\r\n",
      "Requirement already satisfied: packaging>=21.3 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from statsmodels->python-terrier) (23.1)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from beautifulsoup4>=4.4.1->ir-datasets>=0.3.2->python-terrier) (2.5)\r\n",
      "Requirement already satisfied: six in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from patsy>=0.5.4->statsmodels->python-terrier) (1.16.0)\r\n",
      "Requirement already satisfied: cbor>=1.0.0 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from trec-car-tools>=2.5.4->ir-datasets>=0.3.2->python-terrier) (1.0.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install python-terrier\n",
    "\n",
    "import pyterrier as pt\n",
    "if not pt.started():\n",
    "    pt.init()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T14:38:11.338033Z",
     "start_time": "2024-03-19T14:38:10.372487Z"
    }
   },
   "id": "8912d0f4a7342bce"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Dataset\n",
    "\n",
    "Loads the MS MARCO Passage Ranking dataset for the TREC 2020 Deep Learning Track, which will be used for the information retrieval tasks."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7da56acefc3ca897"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21cbb033",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T14:35:32.395654Z",
     "start_time": "2024-03-19T14:35:32.392936Z"
    }
   },
   "outputs": [],
   "source": [
    "# Example of loading a dataset from PyTerrier\n",
    "dataset = pt.get_dataset('irds:msmarco-passage/trec-dl-2020')\n",
    "# For custom datasets, you'd typically load them into a dataframe or similar structure"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Topics\n",
    "\n",
    "Retrieves and prints the first few search queries (topics) from the dataset. These are the queries that will be used to evaluate the retrieval system."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "406d1fe6e279127d"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03cb029c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T14:35:32.409273Z",
     "start_time": "2024-03-19T14:35:32.395830Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "       qid                                       query\n0  1030303                          who is aziz hashim\n1  1037496                          who is rep scalise\n2  1043135            who killed nicholas ii of russia\n3  1045109                     who owns barnhart crane\n4  1049519  who said no one can make you feel inferior",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>qid</th>\n      <th>query</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1030303</td>\n      <td>who is aziz hashim</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1037496</td>\n      <td>who is rep scalise</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1043135</td>\n      <td>who killed nicholas ii of russia</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1045109</td>\n      <td>who owns barnhart crane</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1049519</td>\n      <td>who said no one can make you feel inferior</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics = dataset.get_topics()\n",
    "topics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Qrels\n",
    "Loads the relevance judgments (qrels) for the dataset, which indicate which documents are relevant to each query. These are used for evaluation."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ee930cac79856f78"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T14:35:32.453023Z",
     "start_time": "2024-03-19T14:35:32.407650Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "     qid    docno  label iteration\n0  23849  1020327      2         0\n1  23849  1034183      3         0\n2  23849  1120730      0         0\n3  23849  1139571      1         0\n4  23849  1143724      0         0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>qid</th>\n      <th>docno</th>\n      <th>label</th>\n      <th>iteration</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>23849</td>\n      <td>1020327</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>23849</td>\n      <td>1034183</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>23849</td>\n      <td>1120730</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>23849</td>\n      <td>1139571</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>23849</td>\n      <td>1143724</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qrels = dataset.get_qrels()\n",
    "qrels.head()"
   ],
   "id": "819a40ff2dc7a5e9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Access the Corpus\n",
    "\n",
    "Retrieves the first document from the corpus using an iterator. This demonstrates how to access documents in the dataset."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "30d70233721e891a"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "msmarco-passage/trec-dl-2020 documents:   0%|          | 0/8841823 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'The presence of communication amid scientific minds was equally important to the success of the Manhattan Project as scientific intellect was. The only cloud hanging over the impressive achievement of the atomic researchers and engineers is what their success truly meant; hundreds of thousands of innocent lives obliterated.', 'docno': '0'}\n"
     ]
    }
   ],
   "source": [
    "corpus_iter = dataset.get_corpus_iter()\n",
    "\n",
    "# Convert to an iterator\n",
    "corpus_iterator = iter(corpus_iter)\n",
    "\n",
    "first_doc = next(corpus_iterator)\n",
    "print(first_doc)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T14:35:32.454662Z",
     "start_time": "2024-03-19T14:35:32.428232Z"
    }
   },
   "id": "34c3b2002146429"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "24434cb559f8834"
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# Building and Evaluating the Retrieval System\n",
    "\n",
    "## Index the Corpus\n",
    "\n",
    "Indexes the documents in the corpus, preparing them for retrieval. The documents are stored in a specified directory (`./index_path`)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "84185cd77971f62c"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T14:40:42.384828Z",
     "start_time": "2024-03-19T14:40:42.378485Z"
    }
   },
   "outputs": [],
   "source": [
    "indexer = pt.index.IterDictIndexer(\"./index_path\", stemmer=\"porter\", stopwords=\"terrier\")\n",
    "# index_ref = indexer.index(corpus_iter)"
   ],
   "id": "116a4e67e6829bca"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Configure Retrieval Model\n",
    "Configures the retrieval model to use the BM25 weighting model for ranking documents in response to queries."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "95ca1c9088481f10"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# Configure the retrieval model\n",
    "bm25 = pt.BatchRetrieve(indexer, wmodel=\"BM25\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T14:43:14.351131Z",
     "start_time": "2024-03-19T14:43:13.642443Z"
    }
   },
   "id": "871842303b1a7363"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "tf_idf = pt.BatchRetrieve(indexer, wmodel=\"TF_IDF\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T14:43:15.000652Z",
     "start_time": "2024-03-19T14:43:14.352126Z"
    }
   },
   "id": "937b187139015250"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TODO: Run queries and evaluate the retrieval system \n",
    "\n",
    "We can now run an experiment that evaluates both models on the same data. For better readability, we assign custom names to both approaches.\n",
    "Comparing the approaches in the same experiment allows us to automatically have statistical significance testing performed. By setting baseline=0, we tell the function to compute the  $p$-values with respect to the first approach (TF-IDF). Furthermore, PyTerrier supports a number of correction methods; here, we apply Bonferroni correction:\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bcf3204b01ada1a6"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "     name     RR@10   nDCG@20        AP\n0  TF-IDF  0.802102  0.479753  0.358072\n1    BM25  0.802102  0.479866  0.358724",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>RR@10</th>\n      <th>nDCG@20</th>\n      <th>AP</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>TF-IDF</td>\n      <td>0.802102</td>\n      <td>0.479753</td>\n      <td>0.358072</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>BM25</td>\n      <td>0.802102</td>\n      <td>0.479866</td>\n      <td>0.358724</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyterrier.measures import RR, nDCG, MAP\n",
    "from pathlib import Path\n",
    "\n",
    "results_dir = Path(\"results\")\n",
    "results_dir.mkdir(exist_ok=True)\n",
    "\n",
    "pt.Experiment(\n",
    "    [tf_idf, bm25],\n",
    "    dataset.get_topics(),\n",
    "    dataset.get_qrels(),\n",
    "    names=[\"TF-IDF\", \"BM25\"],\n",
    "    eval_metrics=[RR @ 10, nDCG @ 20, MAP],\n",
    "    save_dir=str(results_dir),\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T14:46:46.926348Z",
     "start_time": "2024-03-19T14:46:20.420561Z"
    }
   },
   "id": "170adc2fe68cba38"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "613310c7c960a04"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
