{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T20:28:04.127480Z",
     "start_time": "2024-03-26T20:28:02.405219Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-terrier in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (0.10.0)\r\n",
      "Requirement already satisfied: numpy in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (1.26.4)\r\n",
      "Requirement already satisfied: pandas in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (2.2.0)\r\n",
      "Requirement already satisfied: wget in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (3.2)\r\n",
      "Requirement already satisfied: tqdm in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (4.65.0)\r\n",
      "Requirement already satisfied: pyjnius>=1.4.2 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (1.6.1)\r\n",
      "Requirement already satisfied: matchpy in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (0.5.5)\r\n",
      "Requirement already satisfied: scikit-learn in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (1.4.0)\r\n",
      "Requirement already satisfied: deprecated in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (1.2.14)\r\n",
      "Requirement already satisfied: chest in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (0.2.3)\r\n",
      "Requirement already satisfied: scipy in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (1.11.4)\r\n",
      "Requirement already satisfied: requests in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (2.31.0)\r\n",
      "Requirement already satisfied: joblib in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (1.3.2)\r\n",
      "Requirement already satisfied: nptyping==1.4.4 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (1.4.4)\r\n",
      "Requirement already satisfied: more-itertools in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (10.2.0)\r\n",
      "Requirement already satisfied: ir-datasets>=0.3.2 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (0.5.6)\r\n",
      "Requirement already satisfied: jinja2 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (3.1.3)\r\n",
      "Requirement already satisfied: statsmodels in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (0.14.1)\r\n",
      "Requirement already satisfied: ir-measures>=0.3.1 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (0.3.3)\r\n",
      "Requirement already satisfied: dill in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (0.3.8)\r\n",
      "Requirement already satisfied: pytrec-eval-terrier>=0.5.3 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (0.5.6)\r\n",
      "Requirement already satisfied: typish>=1.7.0 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from nptyping==1.4.4->python-terrier) (1.9.3)\r\n",
      "Requirement already satisfied: beautifulsoup4>=4.4.1 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier) (4.12.2)\r\n",
      "Requirement already satisfied: inscriptis>=2.2.0 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier) (2.4.0.1)\r\n",
      "Requirement already satisfied: lxml>=4.5.2 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier) (5.1.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier) (6.0.1)\r\n",
      "Requirement already satisfied: trec-car-tools>=2.5.4 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier) (2.6)\r\n",
      "Requirement already satisfied: lz4>=3.1.10 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier) (4.3.3)\r\n",
      "Requirement already satisfied: warc3-wet>=0.2.3 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier) (0.2.3)\r\n",
      "Requirement already satisfied: warc3-wet-clueweb09>=0.2.5 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier) (0.2.5)\r\n",
      "Requirement already satisfied: zlib-state>=0.1.3 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier) (0.1.6)\r\n",
      "Requirement already satisfied: ijson>=3.1.3 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier) (3.2.3)\r\n",
      "Requirement already satisfied: pyautocorpus>=0.1.1 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier) (0.1.12)\r\n",
      "Requirement already satisfied: unlzw3>=0.2.1 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier) (0.2.2)\r\n",
      "Requirement already satisfied: cwl-eval>=1.0.10 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from ir-measures>=0.3.1->python-terrier) (1.0.12)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from requests->python-terrier) (2.0.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from requests->python-terrier) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from requests->python-terrier) (2.1.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from requests->python-terrier) (2024.2.2)\r\n",
      "Requirement already satisfied: heapdict in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from chest->python-terrier) (1.0.1)\r\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from deprecated->python-terrier) (1.14.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from jinja2->python-terrier) (2.1.3)\r\n",
      "Requirement already satisfied: multiset<3.0,>=2.0 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from matchpy->python-terrier) (2.1.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from pandas->python-terrier) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from pandas->python-terrier) (2023.3.post1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from pandas->python-terrier) (2024.1)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from scikit-learn->python-terrier) (3.3.0)\r\n",
      "Requirement already satisfied: patsy>=0.5.4 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from statsmodels->python-terrier) (0.5.6)\r\n",
      "Requirement already satisfied: packaging>=21.3 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from statsmodels->python-terrier) (23.1)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from beautifulsoup4>=4.4.1->ir-datasets>=0.3.2->python-terrier) (2.5)\r\n",
      "Requirement already satisfied: six in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from patsy>=0.5.4->statsmodels->python-terrier) (1.16.0)\r\n",
      "Requirement already satisfied: cbor>=1.0.0 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from trec-car-tools>=2.5.4->ir-datasets>=0.3.2->python-terrier) (1.0.0)\r\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install python-terrier\n",
    "import pyterrier as pt\n",
    "if not pt.started():\n",
    "    pt.init()\n",
    "\n",
    "from transformers import BertModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from pyterrier.measures import RR, nDCG, MAP\n",
    "# Ensure NLTK data is downloaded only once\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "beafbb0455e0ffc8"
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d0b2ad49607e9ca7",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T20:28:04.174186Z",
     "start_time": "2024-03-26T20:28:04.128424Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "msmarco-passage/trec-dl-2020 documents:   0%|          | 0/8841823 [11:49<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# Example of loading a dataset from PyTerrier\n",
    "dataset = pt.get_dataset('irds:msmarco-passage/trec-dl-2020')\n",
    "\n",
    "topics = dataset.get_topics()\n",
    "qrels = dataset.get_qrels()\n",
    "corpus_iter = dataset.get_corpus_iter()\n",
    "# Convert to an iterator\n",
    "corpus_iterator = iter(corpus_iter)\n",
    "first_doc = next(corpus_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "data": {
      "text/plain": "       qid                                       query\n0  1030303                          who is aziz hashim\n1  1037496                          who is rep scalise\n2  1043135            who killed nicholas ii of russia\n3  1045109                     who owns barnhart crane\n4  1049519  who said no one can make you feel inferior",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>qid</th>\n      <th>query</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1030303</td>\n      <td>who is aziz hashim</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1037496</td>\n      <td>who is rep scalise</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1043135</td>\n      <td>who killed nicholas ii of russia</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1045109</td>\n      <td>who owns barnhart crane</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1049519</td>\n      <td>who said no one can make you feel inferior</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T20:28:04.180477Z",
     "start_time": "2024-03-26T20:28:04.174714Z"
    }
   },
   "id": "16535d9f9cb17283"
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "data": {
      "text/plain": "     qid    docno  label iteration\n0  23849  1020327      2         0\n1  23849  1034183      3         0\n2  23849  1120730      0         0\n3  23849  1139571      1         0\n4  23849  1143724      0         0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>qid</th>\n      <th>docno</th>\n      <th>label</th>\n      <th>iteration</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>23849</td>\n      <td>1020327</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>23849</td>\n      <td>1034183</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>23849</td>\n      <td>1120730</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>23849</td>\n      <td>1139571</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>23849</td>\n      <td>1143724</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qrels.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T20:28:04.187039Z",
     "start_time": "2024-03-26T20:28:04.179911Z"
    }
   },
   "id": "9d7b793eada6f871"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load models"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6f9e1515d8868ea"
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c2d27d527d1cec7a",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T20:28:06.153675Z",
     "start_time": "2024-03-26T20:28:04.186032Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "BertClassifier(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (classification): Linear(in_features=768, out_features=2, bias=True)\n)"
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BertClassifier(nn.Module):\n",
    "    def __init__(self, num_labels=2):\n",
    "        super(BertClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        # Align the layer names with the checkpoint\n",
    "        self.classification = nn.Linear(768, num_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, token_type_ids=None):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        logits = self.classification(pooled_output)\n",
    "        return logits\n",
    "\n",
    "# Initialize the model\n",
    "classifier_model = BertClassifier()\n",
    "\n",
    "# Load the checkpoint\n",
    "model_path = './model/doc_baseline.ckpt'\n",
    "checkpoint = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "\n",
    "# Extract the state_dict, assuming the state dict is saved under 'state_dict'\n",
    "model_state_dict = checkpoint['state_dict']\n",
    "\n",
    "# Adjust keys in the state_dict as needed\n",
    "adjusted_model_state_dict = {}\n",
    "for key, value in model_state_dict.items():\n",
    "    # Remove the 'model.' prefix and handle the 'classifier' to 'classification' naming difference\n",
    "    new_key = key.replace('model.', '').replace('classification', 'classifier')\n",
    "    if 'position_ids' not in new_key:  # Ignore 'bert.embeddings.position_ids'\n",
    "        adjusted_model_state_dict[new_key] = value\n",
    "\n",
    "# Load the adjusted state dict\n",
    "classifier_model.load_state_dict(adjusted_model_state_dict, strict=False)\n",
    "classifier_model.eval()  # Set the model to evaluation mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [
    {
     "data": {
      "text/plain": "DocQuery2DocModel(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (classification): Linear(in_features=768, out_features=2, bias=True)\n)"
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DocQuery2DocModel(nn.Module):\n",
    "    def __init__(self, num_labels=2):\n",
    "        super(DocQuery2DocModel, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        # Align the layer names with the checkpoint\n",
    "        self.classification = nn.Linear(768, num_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, token_type_ids=None):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        logits = self.classification(pooled_output)\n",
    "        return logits\n",
    "\n",
    "# Initialize your model\n",
    "doc_query2doc_model = DocQuery2DocModel()\n",
    "\n",
    "# Load the checkpoint\n",
    "model_path = './model/wetransfer_model-1-doc2query-all-rankers_2024-03-21_1327/doc_query2doc.ckpt'\n",
    "checkpoint = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "\n",
    "# Assuming the checkpoint is compatible with the model architecture\n",
    "doc_query2doc_model.load_state_dict(checkpoint, strict=False)\n",
    "\n",
    "doc_query2doc_model.eval()  # Set the model to evaluation mode"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T20:36:52.919152Z",
     "start_time": "2024-03-26T20:36:51.856942Z"
    }
   },
   "id": "e58fad53b5403e42"
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [
    {
     "data": {
      "text/plain": "DocQuery2DocModel(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (classification): Linear(in_features=768, out_features=2, bias=True)\n)"
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DocQuery2DocModel(nn.Module):\n",
    "    def __init__(self, num_labels=2):\n",
    "        super(DocQuery2DocModel, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        # Align the layer names with the checkpoint\n",
    "        self.classification = nn.Linear(768, num_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, token_type_ids=None):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        logits = self.classification(pooled_output)\n",
    "        return logits\n",
    "\n",
    "# Initialize your model\n",
    "doc_query2doc_model = DocQuery2DocModel()\n",
    "\n",
    "# Load the checkpoint\n",
    "model_path = './model/wetransfer_model-1-doc2query-all-rankers_2024-03-21_1327/doc_query2doc.ckpt'\n",
    "checkpoint = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "\n",
    "# Assuming the checkpoint is compatible with the model architecture\n",
    "doc_query2doc_model.load_state_dict(checkpoint, strict=False)\n",
    "\n",
    "doc_query2doc_model.eval()  # Set the model to evaluation mode"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T20:36:51.544900Z",
     "start_time": "2024-03-26T20:36:50.137784Z"
    }
   },
   "id": "5122e7df8dd4b71e"
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [
    {
     "data": {
      "text/plain": "DavinciDocContextModel(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (classification): Linear(in_features=768, out_features=1, bias=True)\n)"
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DavinciDocContextModel(nn.Module):\n",
    "    def __init__(self, num_labels=1):  # Adjusted num_labels to 1 to match checkpoint\n",
    "        super(DavinciDocContextModel, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.classification = nn.Linear(768, num_labels)  # This layer now matches the checkpoint\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, token_type_ids=None):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        logits = self.classification(pooled_output)\n",
    "        return logits\n",
    "\n",
    "# Initialize your model with the corrected number of labels\n",
    "davinci_doc_context_model = DavinciDocContextModel()\n",
    "\n",
    "# Load the checkpoint\n",
    "model_path = './model/doc_davinci_doc_context.ckpt'  # Adjust this path to your checkpoint's location\n",
    "checkpoint = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "\n",
    "# Load the model weights from the checkpoint\n",
    "davinci_doc_context_model.load_state_dict(checkpoint['state_dict'], strict=False)  # Use strict=False for flexibility\n",
    "\n",
    "davinci_doc_context_model.eval()  # Set the model to evaluation mode\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T20:36:39.716596Z",
     "start_time": "2024-03-26T20:36:38.289549Z"
    }
   },
   "id": "1a1ab93ec39df365"
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "3cf48aca4b8b0c62",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T20:28:07.196862Z",
     "start_time": "2024-03-26T20:28:07.187654Z"
    }
   },
   "outputs": [],
   "source": [
    "class TextPreprocessor:\n",
    "    def __init__(self):\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        self.stemmer = PorterStemmer()\n",
    "\n",
    "    def tokenize(self, text: str):\n",
    "        return word_tokenize(text)\n",
    "\n",
    "    def normalize(self, tokens):\n",
    "        return [re.sub(r'\\W+', '', token.lower()) for token in tokens if re.sub(r'\\W+', '', token.lower())]\n",
    "\n",
    "    def stopping(self, tokens):\n",
    "        return [token for token in tokens if token not in self.stop_words]\n",
    "\n",
    "    def stemming(self, tokens):\n",
    "        return [self.stemmer.stem(token) for token in tokens]\n",
    "\n",
    "    def preprocess(self, query: str, use_tokenize=True, use_normalize=True, use_stopping=True, use_stemming=False):\n",
    "        if query is None or not isinstance(query, str):\n",
    "            raise ValueError(\"Input query must be a non-empty string\")\n",
    "        tokens = self.tokenize(query) if use_tokenize else query.split()\n",
    "        if use_normalize: tokens = self.normalize(tokens)\n",
    "        if use_stopping: tokens = self.stopping(tokens)\n",
    "        if use_stemming: tokens = self.stemming(tokens)\n",
    "        return ' '.join(tokens)\n",
    "\n",
    "\n",
    "def preprocess_queries(query: str) -> str:\n",
    "    preprocessor = TextPreprocessor()\n",
    "    return preprocessor.preprocess(query, use_tokenize=True, use_normalize=True, use_stopping=True, use_stemming=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What is the best framework for AI and ee?']\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ContextAwareQueryRewriter:\n",
    "    def __init__(self, classifier_model, doc_query_model, davinci_doc_context_model, tokenizer):\n",
    "        self.classifier_model = classifier_model\n",
    "        self.doc_query_model = doc_query_model\n",
    "        self.davinci_doc_context_model = davinci_doc_context_model\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def classify_query(self, query):\n",
    "        \"\"\"\n",
    "        Classification Phase: Determines whether a query needs rewriting based on ambiguity or specificity.\n",
    "        :param query: \n",
    "        :return: \n",
    "        \"\"\"\n",
    "        inputs = self.tokenizer(query, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        with torch.no_grad():\n",
    "            output = self.classifier_model(**inputs)\n",
    "        logits = output.logits if hasattr(output, 'logits') else output\n",
    "        category = torch.argmax(F.log_softmax(logits, dim=1), dim=1).item()\n",
    "        # Assuming 0 is \"does not need rewriting\" and 1 is \"needs rewriting\"\n",
    "        needs_rewriting = category == 1\n",
    "        return needs_rewriting\n",
    "\n",
    "    def rewrite_query(self, query, context):\n",
    "        \"\"\"\n",
    "        Context Incorporation: Utilizes relevant context to guide the rewriting process, ensuring the rewritten query aligns better with user intent.\n",
    "        :param query: \n",
    "        :param context: \n",
    "        :return: \n",
    "        \"\"\"\n",
    "        # Preprocess query and context together as input for the model\n",
    "        inputs = self.tokenizer.encode_plus(text=query, text_pair=context, return_tensors='pt', max_length=512, truncation=True, padding=\"max_length\")\n",
    "\n",
    "        # Decide which model to use based on the context or other criteria\n",
    "        model = self.select_model_based_on_context(context)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        rewritten_query = self.process_outputs_to_query(outputs)\n",
    "        return rewritten_query\n",
    "\n",
    "    def select_model_based_on_context(self, context):\n",
    "        # Example logic based on context length and specific keywords\n",
    "        long_context_threshold = 100  # Threshold for considering a context as 'long'\n",
    "        specific_keywords = ['advanced', 'comparison', 'evaluate']  # Keywords indicating complex analysis might be required\n",
    "    \n",
    "        # Check for specific keywords in the context\n",
    "        contains_specific_keyword = any(keyword in context.lower() for keyword in specific_keywords)\n",
    "    \n",
    "        # If the context is long or contains specific keywords, use davinci_doc_context_model\n",
    "        if len(context.split()) > long_context_threshold or contains_specific_keyword:\n",
    "            return self.davinci_doc_context_model\n",
    "        else:\n",
    "            return self.doc_query_model\n",
    "\n",
    "\n",
    "    def process_outputs_to_query(self, outputs):\n",
    "        # Assuming the outputs include token IDs that need to be converted to text\n",
    "        # This is a simplification; actual implementation may need to handle logits, apply softmax, etc.\n",
    "    \n",
    "        # Convert token IDs to text\n",
    "        # Note: This step assumes the model outputs token IDs directly; adjust based on your model's output format.\n",
    "        token_ids = outputs[0] if isinstance(outputs, tuple) else outputs\n",
    "    \n",
    "        # Decode the token IDs back to text\n",
    "        rewritten_query = self.tokenizer.decode(token_ids, skip_special_tokens=True)\n",
    "    \n",
    "        return rewritten_query\n",
    "\n",
    "\n",
    "    def transform(self, queries, contexts):\n",
    "        rewritten_queries = []\n",
    "        for query, context in zip(queries, contexts):\n",
    "            if self.classify_query(query):\n",
    "                rewritten_query = self.rewrite_query(query, context)\n",
    "                rewritten_queries.append(rewritten_query)\n",
    "            else:\n",
    "                # If the query does not need rewriting, append it as is.\n",
    "                rewritten_queries.append(query)\n",
    "        return rewritten_queries\n",
    "\n",
    "# Assuming classifier_model, doc_query_model, and davinci_doc_context_model are already defined and loaded\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "context_aware_rewriter = ContextAwareQueryRewriter(classifier_model, doc_query2doc_model, davinci_doc_context_model, tokenizer)\n",
    "\n",
    "# Example usage (continued from previous code snippet)\n",
    "rewritten_queries = context_aware_rewriter.transform(\n",
    "    ['What is the best framework for AI and ee?'],\n",
    "    ['This question seeks to compare different artificial intelligence frameworks based on their efficiencies, usability, and support for advanced features.']\n",
    ")\n",
    "print(rewritten_queries)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T20:47:54.200835Z",
     "start_time": "2024-03-26T20:47:54.024835Z"
    }
   },
   "id": "158b0090a11a4d9d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 1: Extracting Original Queries\n",
    "\n",
    "You've already loaded the dataset and accessed the topics, which contain the queries. The code snippet you've shown extracts the queries from the `topics` DataFrame provided by PyTerrier:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dcfaf86fc74814ce"
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [],
   "source": [
    "# Assuming you've already loaded the dataset and have the 'topics' DataFrame\n",
    "original_queries = [topic['query'] for topic_id, topic in topics.iterrows()]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T20:28:07.203587Z",
     "start_time": "2024-03-26T20:28:07.199804Z"
    }
   },
   "id": "b433065d9872a592"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 2: Preprocessing Queries\n",
    "\n",
    "You've defined a `TextPreprocessor` class for preprocessing queries. You can apply this preprocessing to each of the original queries to get them ready for the rewriting process:\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "62d5311335373f64"
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [],
   "source": [
    "# preprocessor = TextPreprocessor()\n",
    "# preprocessed_queries = [preprocessor.preprocess(query) for query in original_queries]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T20:28:07.241712Z",
     "start_time": "2024-03-26T20:28:07.204191Z"
    }
   },
   "id": "545af3a0edef4845"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 3: Rewriting Queries\n",
    "\n",
    "You've also created a `QueryRewriter` class that takes in a model and a tokenizer to rewrite queries based on a certain logic (in your case, this logic depends on the predictions from a BertClassifier model). Initialize the `QueryRewriter` with the necessary model and tokenizer, and then use it to rewrite the preprocessed queries:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "720525af9081cece"
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Initialize the tokenizer for BERT\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Initialize the QueryRewriter with your model and tokenizer\n",
    "query_rewriter = ContextAwareQueryRewriter(classifier_model,doc_query2doc_model, tokenizer)\n",
    "\n",
    "# Rewrite the preprocessed queries\n",
    "rewritten_queries = query_rewriter.transform(original_queries)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T20:28:28.759825Z",
     "start_time": "2024-03-26T20:28:07.206818Z"
    }
   },
   "id": "35f27a036be565b2"
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rewritten queries: \n",
      "['who is aziz hashim discounts', 'who is rep scalise discounts', 'who killed nicholas ii of russia discounts', 'who owns barnhart crane discounts', 'who said no one can make you feel inferior discounts', 'who sings monk theme song discounts', 'who was the highest career passer rating in the nfl for sale', 'why do hunters pattern their shotguns discounts', 'why do some places on my scalp feel sore for sale', 'why is pete rose banned from hall of fame discounts']\n",
      "\n",
      "Original queries: \n",
      "['who is aziz hashim', 'who is rep scalise', 'who killed nicholas ii of russia', 'who owns barnhart crane', 'who said no one can make you feel inferior', 'who sings monk theme song', 'who was the highest career passer rating in the nfl', 'why do hunters pattern their shotguns', 'why do some places on my scalp feel sore', 'why is pete rose banned from hall of fame']\n"
     ]
    }
   ],
   "source": [
    "print(\"Rewritten queries: \")\n",
    "print(rewritten_queries[:10])\n",
    "print(\"\\nOriginal queries: \")\n",
    "print(original_queries[:10])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T20:29:37.555808Z",
     "start_time": "2024-03-26T20:29:37.551850Z"
    }
   },
   "id": "b5dc4f5b256ac445"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluating Rewritten vs. Original Queries with Doc MSMARCO Reranked Models\n",
    "\n",
    "### Objective\n",
    "\n",
    "The goal is to utilize the four doc_msmarco reranked models to compare the performance of rewritten queries against original queries.\n",
    "\n",
    "### Location of Reranked Models\n",
    "\n",
    "The reranked models are stored within the `doc_msmarco` directory, under the `model` folder. Here's the structure:\n",
    "\n",
    "```\n",
    "model/\n",
    "├── doc_baseline.ckpt\n",
    "├── doc_davinci_doc_context.ckpt\n",
    "└── wetransfer_model-1-doc2query-all-rankers_2024-03-21_1327/\n",
    "    ├── best_rank_list/\n",
    "    │   └── doc_msmarco/\n",
    "    │       ├── doc_attention_2_davinci_final_3e-4.tsv\n",
    "    │       ├── doc_davinci03_doc_context_400tok_5e-4.tsv\n",
    "    │       ├── doc_linear_2_davinci_final_1e-4.tsv\n",
    "    │       └── doc_query_2_doc_3e-4.tsv\n",
    "    └── doc_query2doc.ckpt\n",
    "```\n",
    "\n",
    "### Procedure\n",
    "\n",
    "1. **Retrieve Documents**: Initially, documents are fetched from the MS MARCO datasets for the purpose of reranking.\n",
    "\n",
    "2. **Reranking**: Utilize the retrieved documents along with the queries (both original and rewritten) to perform reranking using the models specified above.\n",
    "\n",
    "3. **Evaluation**: Assess the reranking process to determine the effectiveness of rewritten queries in comparison to the original ones."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c0d73d15c5c715dc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 1: Indexing the Corpus\n",
    "\n",
    "Before we can retrieve and rerank documents based on queries, we need to ensure that the documents are indexed. You've mentioned creating an index but commented out the relevant code. Here's how you can do it properly with Pyterrier"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7454fc2217c8bf8f"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "fcc6b1fc0be71c91"
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index already exists, loading from disk.\n"
     ]
    }
   ],
   "source": [
    "index_location = str(Path(\"index\").absolute())\n",
    "index_exists = os.path.isfile(os.path.join(index_location, \"data.properties\"))\n",
    "\n",
    "if not index_exists:\n",
    "    indexer = pt.IterDictIndexer(index_location)\n",
    "    index_ref = indexer.index(corpus_iter)\n",
    "    print(\"Indexing completed.\")\n",
    "else:\n",
    "    print(\"Index already exists, loading from disk.\")\n",
    "    index_ref = index_location"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T20:28:28.766943Z",
     "start_time": "2024-03-26T20:28:28.764105Z"
    }
   },
   "id": "7f344426c854e676"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 2: Retrieving Documents\n",
    "\n",
    "You need to use the created index to retrieve documents based on both the original and rewritten queries. You have already outlined this step correctly, but make sure that `index` is correctly initialized using the `index_ref` from the indexing step:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4929c9c9679a10c1"
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [],
   "source": [
    "# Assuming original_queries and rewritten_queries are your lists of queries\n",
    "query_ids = range(1, len(original_queries) + 1)  # Generating query IDs\n",
    "\n",
    "# Converting original queries to a DataFrame\n",
    "original_queries_df = pd.DataFrame({\n",
    "    'qid': query_ids,\n",
    "    'query': original_queries\n",
    "})\n",
    "\n",
    "# Converting rewritten queries to a DataFrame\n",
    "rewritten_queries_df = pd.DataFrame({\n",
    "    'qid': query_ids,\n",
    "    'query': rewritten_queries\n",
    "})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T20:28:28.771356Z",
     "start_time": "2024-03-26T20:28:28.768392Z"
    }
   },
   "id": "d2a43b70db85b5f4"
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [],
   "source": [
    "# Initialize index from the created index reference\n",
    "index = pt.IndexFactory.of(index_ref)\n",
    "\n",
    "# Retrieve documents for both original and rewritten queries using BM25\n",
    "original_res = pt.BatchRetrieve(index, wmodel=\"BM25\").transform(original_queries_df)\n",
    "rewritten_res = pt.BatchRetrieve(index, wmodel=\"BM25\").transform(rewritten_queries_df)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T20:28:57.016285Z",
     "start_time": "2024-03-26T20:28:28.771521Z"
    }
   },
   "id": "a2efe3df97d3ff87"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 3: Reranking the Results\n",
    "\n",
    "After retrieving the initial set of documents for both the original and rewritten queries, the next step is to rerank these results. You've outlined the process, assuming you have a `reranker` defined. This reranker could be any model or method that takes a set of retrieved documents and reorders them based on relevance. Let's proceed with the assumption:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "52572a40f2bada83"
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [
    {
     "data": {
      "text/plain": "      qid placeholder     docid  rank     score  \\\n0  966413          Q0   D721816     1  5.391621   \n1  966413          Q0   D104404     2  5.362526   \n2  966413          Q0  D3547764     3  5.334213   \n3  966413          Q0   D160447     4  5.331561   \n4  966413          Q0   D147193     5  5.302257   \n\n                                          identifier  \n0  msmarco_doc_davinci03_doc_context_1200_400tok_...  \n1  msmarco_doc_davinci03_doc_context_1200_400tok_...  \n2  msmarco_doc_davinci03_doc_context_1200_400tok_...  \n3  msmarco_doc_davinci03_doc_context_1200_400tok_...  \n4  msmarco_doc_davinci03_doc_context_1200_400tok_...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>qid</th>\n      <th>placeholder</th>\n      <th>docid</th>\n      <th>rank</th>\n      <th>score</th>\n      <th>identifier</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>966413</td>\n      <td>Q0</td>\n      <td>D721816</td>\n      <td>1</td>\n      <td>5.391621</td>\n      <td>msmarco_doc_davinci03_doc_context_1200_400tok_...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>966413</td>\n      <td>Q0</td>\n      <td>D104404</td>\n      <td>2</td>\n      <td>5.362526</td>\n      <td>msmarco_doc_davinci03_doc_context_1200_400tok_...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>966413</td>\n      <td>Q0</td>\n      <td>D3547764</td>\n      <td>3</td>\n      <td>5.334213</td>\n      <td>msmarco_doc_davinci03_doc_context_1200_400tok_...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>966413</td>\n      <td>Q0</td>\n      <td>D160447</td>\n      <td>4</td>\n      <td>5.331561</td>\n      <td>msmarco_doc_davinci03_doc_context_1200_400tok_...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>966413</td>\n      <td>Q0</td>\n      <td>D147193</td>\n      <td>5</td>\n      <td>5.302257</td>\n      <td>msmarco_doc_davinci03_doc_context_1200_400tok_...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is how an entry of .tsv looks like: 966413\tQ0\tD660657\t1\t5.271960258483887\tdoc_attention_davinci_2_final_3e-4\n",
    "\n",
    "# Example for loading one reranking file\n",
    "reranking_path = './model/wetransfer_model-1-doc2query-all-rankers_2024-03-21_1327/best_rank_list/doc_msmarco/doc_davinci03_doc_context_400tok_5e-4.tsv'\n",
    "\n",
    "reranking_df = pd.read_csv(\n",
    "    reranking_path,\n",
    "    sep='\\t',\n",
    "    header=None,\n",
    "    names=['qid', 'placeholder', 'docid', 'rank', 'score', 'identifier']\n",
    ")\n",
    "\n",
    "\n",
    "# Display the first few rows to understand its structure\n",
    "reranking_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T20:28:57.044420Z",
     "start_time": "2024-03-26T20:28:57.016738Z"
    }
   },
   "id": "d24fedb90364fcb0"
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [
    {
     "data": {
      "text/plain": "  qid    docid    docno  rank      score               query\n0   1  8726435  8726436     0  54.354218  who is aziz hashim\n1   1  8726432  8726433     1  44.220280  who is aziz hashim\n2   1  8726434  8726435     2  40.514966  who is aziz hashim\n3   1  8726428  8726429     3  39.687092  who is aziz hashim\n4   1  8726436  8726437     4  35.847262  who is aziz hashim",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>qid</th>\n      <th>docid</th>\n      <th>docno</th>\n      <th>rank</th>\n      <th>score</th>\n      <th>query</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>8726435</td>\n      <td>8726436</td>\n      <td>0</td>\n      <td>54.354218</td>\n      <td>who is aziz hashim</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>8726432</td>\n      <td>8726433</td>\n      <td>1</td>\n      <td>44.220280</td>\n      <td>who is aziz hashim</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>8726434</td>\n      <td>8726435</td>\n      <td>2</td>\n      <td>40.514966</td>\n      <td>who is aziz hashim</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>8726428</td>\n      <td>8726429</td>\n      <td>3</td>\n      <td>39.687092</td>\n      <td>who is aziz hashim</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>8726436</td>\n      <td>8726437</td>\n      <td>4</td>\n      <td>35.847262</td>\n      <td>who is aziz hashim</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_res.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T20:28:57.073386Z",
     "start_time": "2024-03-26T20:28:57.041181Z"
    }
   },
   "id": "21eaf62c30039098"
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        qid    docid    docno  rank      score                          query\n",
      "0         1  8726435  8726436     0  54.354218             who is aziz hashim\n",
      "1         1  8726432  8726433     1  44.220280             who is aziz hashim\n",
      "2         1  8726434  8726435     2  40.514966             who is aziz hashim\n",
      "3         1  8726428  8726429     3  39.687092             who is aziz hashim\n",
      "4         1  8726436  8726437     4  35.847262             who is aziz hashim\n",
      "...     ...      ...      ...   ...        ...                            ...\n",
      "193657  200  2431418  2431419   995  13.890963  definition of attempted arson\n",
      "193658  200  2765611  2765612   996  13.890963  definition of attempted arson\n",
      "193659  200  4400076  4400077   997  13.890963  definition of attempted arson\n",
      "193660  200  5041481  5041482   998  13.890963  definition of attempted arson\n",
      "193661  200  6031518  6031519   999  13.890963  definition of attempted arson\n",
      "\n",
      "[193662 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print(original_res)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T20:28:57.082983Z",
     "start_time": "2024-03-26T20:28:57.044537Z"
    }
   },
   "id": "795a0941d6a82fe8"
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of         qid    docid    docno  rank      score                          query  \\\n",
      "0         1  8726435  8726436     0  54.354218             who is aziz hashim   \n",
      "1         1  8726432  8726433     1  44.220280             who is aziz hashim   \n",
      "2         1  8726434  8726435     2  40.514966             who is aziz hashim   \n",
      "3         1  8726428  8726429     3  39.687092             who is aziz hashim   \n",
      "4         1  8726436  8726437     4  35.847262             who is aziz hashim   \n",
      "...     ...      ...      ...   ...        ...                            ...   \n",
      "193657  200  2431418  2431419   995  13.890963  definition of attempted arson   \n",
      "193658  200  2765611  2765612   996  13.890963  definition of attempted arson   \n",
      "193659  200  4400076  4400077   997  13.890963  definition of attempted arson   \n",
      "193660  200  5041481  5041482   998  13.890963  definition of attempted arson   \n",
      "193661  200  6031518  6031519   999  13.890963  definition of attempted arson   \n",
      "\n",
      "        qid_reranked placeholder  rank_reranked  score_reranked identifier  \n",
      "0                NaN         NaN            NaN             NaN        NaN  \n",
      "1                NaN         NaN            NaN             NaN        NaN  \n",
      "2                NaN         NaN            NaN             NaN        NaN  \n",
      "3                NaN         NaN            NaN             NaN        NaN  \n",
      "4                NaN         NaN            NaN             NaN        NaN  \n",
      "...              ...         ...            ...             ...        ...  \n",
      "193657           NaN         NaN            NaN             NaN        NaN  \n",
      "193658           NaN         NaN            NaN             NaN        NaN  \n",
      "193659           NaN         NaN            NaN             NaN        NaN  \n",
      "193660           NaN         NaN            NaN             NaN        NaN  \n",
      "193661           NaN         NaN            NaN             NaN        NaN  \n",
      "\n",
      "[193662 rows x 11 columns]>\n"
     ]
    }
   ],
   "source": [
    "# Convert 'docid' to string in both your results and reranking DataFrame\n",
    "original_res['docid'] = original_res['docid'].astype(str)\n",
    "rewritten_res['docid'] = rewritten_res['docid'].astype(str)\n",
    "reranking_df['docid'] = reranking_df['docid'].astype(str)  # Assuming this column actually refers to 'docid' as discussed\n",
    "\n",
    "# Merging with corrected data types\n",
    "original_res_with_ranks = pd.merge(\n",
    "    original_res,\n",
    "    reranking_df,\n",
    "    on='docid',\n",
    "    how='left',\n",
    "    suffixes=('', '_reranked')\n",
    ")\n",
    "\n",
    "rewritten_res_with_ranks = pd.merge(\n",
    "    rewritten_res,\n",
    "    reranking_df,\n",
    "    on='docid',\n",
    "    how='left',\n",
    "    suffixes=('', '_reranked')\n",
    ")\n",
    "\n",
    "\n",
    "print(original_res_with_ranks.head)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T20:28:57.258362Z",
     "start_time": "2024-03-26T20:28:57.051822Z"
    }
   },
   "id": "a2c511cd539d7715"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 4: Evaluating the Results\n",
    "\n",
    "Finally, to evaluate the effectiveness of the rewritten queries versus the original queries, you'll use PyTerrier's evaluation functionalities. You need to compare the reranked results against the relevance judgments (`qrels`) using various metrics:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aeb837633b6194f3"
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[129], line 17\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpyterrier\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmeasures\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m RR, nDCG, AP\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# Ensure your reranked DataFrames are named appropriately and structured correctly\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# They should have columns ['qid', 'docno', 'score']\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     15\u001B[0m \n\u001B[1;32m     16\u001B[0m \u001B[38;5;66;03m# Display the evaluation results\u001B[39;00m\n\u001B[0;32m---> 17\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mresults\u001B[49m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "from pyterrier.measures import RR, nDCG, AP\n",
    "\n",
    "# Ensure your reranked DataFrames are named appropriately and structured correctly\n",
    "# They should have columns ['qid', 'docno', 'score']\n",
    "\n",
    "# Perform the evaluation using PyTerrier's Experiment function\n",
    "# results = pt.Experiment(\n",
    "#     [original_res_sorted, rewritten_res_sorted],\n",
    "#     topics,  # Your original queries DataFrame\n",
    "#     qrels,  # The qrels DataFrame with relevance judgments\n",
    "#     eval_metrics=[nDCG@10, AP(rel=10), RR(rel=10), nDCG@20],\n",
    "#     names=[\"Original Reranked\", \"Rewritten Reranked\"],\n",
    "#     baseline=0,  # Optionally specify which result set is considered the 'baseline' for comparison\n",
    "# )\n",
    "\n",
    "# Display the evaluation results\n",
    "print(results)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T20:28:57.275367Z",
     "start_time": "2024-03-26T20:28:57.254240Z"
    }
   },
   "id": "6d1c30176aea20aa"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
