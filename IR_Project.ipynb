{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T18:00:15.236232Z",
     "start_time": "2024-03-26T18:00:13.759980Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-terrier in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (0.10.0)\r\n",
      "Requirement already satisfied: numpy in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (1.26.4)\r\n",
      "Requirement already satisfied: pandas in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (2.2.0)\r\n",
      "Requirement already satisfied: wget in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (3.2)\r\n",
      "Requirement already satisfied: tqdm in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (4.65.0)\r\n",
      "Requirement already satisfied: pyjnius>=1.4.2 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (1.6.1)\r\n",
      "Requirement already satisfied: matchpy in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (0.5.5)\r\n",
      "Requirement already satisfied: scikit-learn in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (1.4.0)\r\n",
      "Requirement already satisfied: deprecated in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (1.2.14)\r\n",
      "Requirement already satisfied: chest in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (0.2.3)\r\n",
      "Requirement already satisfied: scipy in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (1.11.4)\r\n",
      "Requirement already satisfied: requests in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (2.31.0)\r\n",
      "Requirement already satisfied: joblib in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (1.3.2)\r\n",
      "Requirement already satisfied: nptyping==1.4.4 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (1.4.4)\r\n",
      "Requirement already satisfied: more-itertools in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (10.2.0)\r\n",
      "Requirement already satisfied: ir-datasets>=0.3.2 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (0.5.6)\r\n",
      "Requirement already satisfied: jinja2 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (3.1.3)\r\n",
      "Requirement already satisfied: statsmodels in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (0.14.1)\r\n",
      "Requirement already satisfied: ir-measures>=0.3.1 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (0.3.3)\r\n",
      "Requirement already satisfied: dill in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (0.3.8)\r\n",
      "Requirement already satisfied: pytrec-eval-terrier>=0.5.3 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (0.5.6)\r\n",
      "Requirement already satisfied: typish>=1.7.0 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from nptyping==1.4.4->python-terrier) (1.9.3)\r\n",
      "Requirement already satisfied: beautifulsoup4>=4.4.1 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier) (4.12.2)\r\n",
      "Requirement already satisfied: inscriptis>=2.2.0 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier) (2.4.0.1)\r\n",
      "Requirement already satisfied: lxml>=4.5.2 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier) (5.1.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier) (6.0.1)\r\n",
      "Requirement already satisfied: trec-car-tools>=2.5.4 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier) (2.6)\r\n",
      "Requirement already satisfied: lz4>=3.1.10 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier) (4.3.3)\r\n",
      "Requirement already satisfied: warc3-wet>=0.2.3 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier) (0.2.3)\r\n",
      "Requirement already satisfied: warc3-wet-clueweb09>=0.2.5 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier) (0.2.5)\r\n",
      "Requirement already satisfied: zlib-state>=0.1.3 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier) (0.1.6)\r\n",
      "Requirement already satisfied: ijson>=3.1.3 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier) (3.2.3)\r\n",
      "Requirement already satisfied: pyautocorpus>=0.1.1 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier) (0.1.12)\r\n",
      "Requirement already satisfied: unlzw3>=0.2.1 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier) (0.2.2)\r\n",
      "Requirement already satisfied: cwl-eval>=1.0.10 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from ir-measures>=0.3.1->python-terrier) (1.0.12)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from requests->python-terrier) (2.0.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from requests->python-terrier) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from requests->python-terrier) (2.1.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from requests->python-terrier) (2024.2.2)\r\n",
      "Requirement already satisfied: heapdict in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from chest->python-terrier) (1.0.1)\r\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from deprecated->python-terrier) (1.14.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from jinja2->python-terrier) (2.1.3)\r\n",
      "Requirement already satisfied: multiset<3.0,>=2.0 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from matchpy->python-terrier) (2.1.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from pandas->python-terrier) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from pandas->python-terrier) (2023.3.post1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from pandas->python-terrier) (2024.1)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from scikit-learn->python-terrier) (3.3.0)\r\n",
      "Requirement already satisfied: patsy>=0.5.4 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from statsmodels->python-terrier) (0.5.6)\r\n",
      "Requirement already satisfied: packaging>=21.3 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from statsmodels->python-terrier) (23.1)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from beautifulsoup4>=4.4.1->ir-datasets>=0.3.2->python-terrier) (2.5)\r\n",
      "Requirement already satisfied: six in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from patsy>=0.5.4->statsmodels->python-terrier) (1.16.0)\r\n",
      "Requirement already satisfied: cbor>=1.0.0 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from trec-car-tools>=2.5.4->ir-datasets>=0.3.2->python-terrier) (1.0.0)\r\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install python-terrier\n",
    "import pyterrier as pt\n",
    "if not pt.started():\n",
    "    pt.init()\n",
    "\n",
    "from transformers import BertModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Ensure NLTK data is downloaded only once\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0b2ad49607e9ca7",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T18:00:15.266693Z",
     "start_time": "2024-03-26T18:00:15.233274Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "msmarco-passage/trec-dl-2020 documents:   0%|          | 0/8841823 [02:57<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# Example of loading a dataset from PyTerrier\n",
    "dataset = pt.get_dataset('irds:msmarco-passage/trec-dl-2020')\n",
    "\n",
    "topics = dataset.get_topics()\n",
    "qrels = dataset.get_qrels()\n",
    "corpus_iter = dataset.get_corpus_iter()\n",
    "# Convert to an iterator\n",
    "corpus_iterator = iter(corpus_iter)\n",
    "first_doc = next(corpus_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c2d27d527d1cec7a",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T18:00:16.929558Z",
     "start_time": "2024-03-26T18:00:15.268510Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "BertClassifier(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (classification): Linear(in_features=768, out_features=2, bias=True)\n)"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BertClassifier(nn.Module):\n",
    "    def __init__(self, num_labels=2):\n",
    "        super(BertClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        # Align the layer names with the checkpoint\n",
    "        self.classification = nn.Linear(768, num_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, token_type_ids=None):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        logits = self.classification(pooled_output)\n",
    "        return logits\n",
    "\n",
    "# Initialize the model\n",
    "model = BertClassifier()\n",
    "\n",
    "# Load the checkpoint\n",
    "model_path = './model/doc_baseline.ckpt'\n",
    "checkpoint = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "\n",
    "# Extract the state_dict, assuming the state dict is saved under 'state_dict'\n",
    "model_state_dict = checkpoint['state_dict']\n",
    "\n",
    "# Adjust keys in the state_dict as needed\n",
    "adjusted_model_state_dict = {}\n",
    "for key, value in model_state_dict.items():\n",
    "    # Remove the 'model.' prefix and handle the 'classifier' to 'classification' naming difference\n",
    "    new_key = key.replace('model.', '').replace('classification', 'classifier')\n",
    "    if 'position_ids' not in new_key:  # Ignore 'bert.embeddings.position_ids'\n",
    "        adjusted_model_state_dict[new_key] = value\n",
    "\n",
    "# Load the adjusted state dict\n",
    "model.load_state_dict(adjusted_model_state_dict, strict=False)\n",
    "model.eval()  # Set the model to evaluation mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3cf48aca4b8b0c62",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T18:00:16.935725Z",
     "start_time": "2024-03-26T18:00:16.932597Z"
    }
   },
   "outputs": [],
   "source": [
    "class TextPreprocessor:\n",
    "    def __init__(self):\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        self.stemmer = PorterStemmer()\n",
    "\n",
    "    def tokenize(self, text: str):\n",
    "        return word_tokenize(text)\n",
    "\n",
    "    def normalize(self, tokens):\n",
    "        return [re.sub(r'\\W+', '', token.lower()) for token in tokens if re.sub(r'\\W+', '', token.lower())]\n",
    "\n",
    "    def stopping(self, tokens):\n",
    "        return [token for token in tokens if token not in self.stop_words]\n",
    "\n",
    "    def stemming(self, tokens):\n",
    "        return [self.stemmer.stem(token) for token in tokens]\n",
    "\n",
    "    def preprocess(self, query: str, use_tokenize=True, use_normalize=True, use_stopping=True, use_stemming=False):\n",
    "        if query is None or not isinstance(query, str):\n",
    "            raise ValueError(\"Input query must be a non-empty string\")\n",
    "        tokens = self.tokenize(query) if use_tokenize else query.split()\n",
    "        if use_normalize: tokens = self.normalize(tokens)\n",
    "        if use_stopping: tokens = self.stopping(tokens)\n",
    "        if use_stemming: tokens = self.stemming(tokens)\n",
    "        return ' '.join(tokens)\n",
    "\n",
    "\n",
    "def preprocess_queries(query: str) -> str:\n",
    "    preprocessor = TextPreprocessor()\n",
    "    return preprocessor.preprocess(query, use_tokenize=True, use_normalize=True, use_stopping=True, use_stemming=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "class QueryRewriter(pt.transformer.TransformerBase):\n",
    "    def __init__(self, model, tokenizer):\n",
    "        super(QueryRewriter, self).__init__()\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def transform(self, queries):\n",
    "        rewritten_queries = []\n",
    "        for query in queries:\n",
    "            # Tokenize the query using the BERT tokenizer\n",
    "            inputs = self.tokenizer.encode_plus(query, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "            input_ids = inputs[\"input_ids\"]\n",
    "            attention_mask = inputs[\"attention_mask\"]\n",
    "\n",
    "            # Predict with the model\n",
    "            with torch.no_grad():\n",
    "                output = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                logits = output\n",
    "                predictions = torch.argmax(logits, dim=-1)\n",
    "\n",
    "            # Determine if the query should be rewritten based on model's prediction\n",
    "            if predictions.item() == 1:\n",
    "                rewritten_query = self.rewrite_query(query)\n",
    "            else:\n",
    "                rewritten_query = query\n",
    "\n",
    "            rewritten_queries.append(rewritten_query)\n",
    "        return rewritten_queries\n",
    "\n",
    "\n",
    "    def rewrite_query(self, query):\n",
    "        # TODO: Implement your query rewriting logic here @Sebastiaan & @Marianna\n",
    "        rewritten_query = query\n",
    "        return rewritten_query\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T18:00:16.940771Z",
     "start_time": "2024-03-26T18:00:16.938771Z"
    }
   },
   "id": "158b0090a11a4d9d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 1: Extracting Original Queries\n",
    "\n",
    "You've already loaded the dataset and accessed the topics, which contain the queries. The code snippet you've shown extracts the queries from the `topics` DataFrame provided by PyTerrier:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dcfaf86fc74814ce"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# Assuming you've already loaded the dataset and have the 'topics' DataFrame\n",
    "original_queries = [topic['query'] for topic_id, topic in topics.iterrows()]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T18:00:16.947348Z",
     "start_time": "2024-03-26T18:00:16.945440Z"
    }
   },
   "id": "b433065d9872a592"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 2: Preprocessing Queries\n",
    "\n",
    "You've defined a `TextPreprocessor` class for preprocessing queries. You can apply this preprocessing to each of the original queries to get them ready for the rewriting process:\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "62d5311335373f64"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "preprocessor = TextPreprocessor()\n",
    "preprocessed_queries = [preprocessor.preprocess(query) for query in original_queries]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T18:00:16.973033Z",
     "start_time": "2024-03-26T18:00:16.948333Z"
    }
   },
   "id": "545af3a0edef4845"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 3: Rewriting Queries\n",
    "\n",
    "You've also created a `QueryRewriter` class that takes in a model and a tokenizer to rewrite queries based on a certain logic (in your case, this logic depends on the predictions from a BertClassifier model). Initialize the `QueryRewriter` with the necessary model and tokenizer, and then use it to rewrite the preprocessed queries:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "720525af9081cece"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_3/jggbxqpj77x_m8nr3ll39p5r0000gn/T/ipykernel_88236/2690969965.py:3: DeprecationWarning: Call to deprecated method __init__. (Use pt.Transformer instead of TransformerBase) -- Deprecated since version 0.9.\n",
      "  super(QueryRewriter, self).__init__()\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Initialize the tokenizer for BERT\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Initialize the QueryRewriter with your model and tokenizer\n",
    "query_rewriter = QueryRewriter(model, tokenizer)\n",
    "\n",
    "# Rewrite the preprocessed queries\n",
    "rewritten_queries = query_rewriter.transform(preprocessed_queries)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T18:00:25.043559Z",
     "start_time": "2024-03-26T18:00:16.960966Z"
    }
   },
   "id": "35f27a036be565b2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluating Rewritten vs. Original Queries with Doc MSMARCO Reranked Models\n",
    "\n",
    "### Objective\n",
    "\n",
    "The goal is to utilize the four doc_msmarco reranked models to compare the performance of rewritten queries against original queries.\n",
    "\n",
    "### Location of Reranked Models\n",
    "\n",
    "The reranked models are stored within the `doc_msmarco` directory, under the `model` folder. Here's the structure:\n",
    "\n",
    "```\n",
    "model/\n",
    "├── doc_baseline.ckpt\n",
    "├── doc_davinci_doc_context.ckpt\n",
    "└── wetransfer_model-1-doc2query-all-rankers_2024-03-21_1327/\n",
    "    ├── best_rank_list/\n",
    "    │   └── doc_msmarco/\n",
    "    │       ├── doc_attention_2_davinci_final_3e-4.tsv\n",
    "    │       ├── doc_davinci03_doc_context_400tok_5e-4.tsv\n",
    "    │       ├── doc_linear_2_davinci_final_1e-4.tsv\n",
    "    │       └── doc_query_2_doc_3e-4.tsv\n",
    "    └── doc_query2doc.ckpt\n",
    "```\n",
    "\n",
    "### Procedure\n",
    "\n",
    "1. **Retrieve Documents**: Initially, documents are fetched from the MS MARCO datasets for the purpose of reranking.\n",
    "\n",
    "2. **Reranking**: Utilize the retrieved documents along with the queries (both original and rewritten) to perform reranking using the models specified above.\n",
    "\n",
    "3. **Evaluation**: Assess the reranking process to determine the effectiveness of rewritten queries in comparison to the original ones."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c0d73d15c5c715dc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 1: Indexing the Corpus\n",
    "\n",
    "Before we can retrieve and rerank documents based on queries, we need to ensure that the documents are indexed. You've mentioned creating an index but commented out the relevant code. Here's how you can do it properly with Pyterrier"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7454fc2217c8bf8f"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "fcc6b1fc0be71c91"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index already exists, loading from disk.\n"
     ]
    }
   ],
   "source": [
    "index_location = str(Path(\"index\").absolute())\n",
    "index_exists = os.path.isfile(os.path.join(index_location, \"data.properties\"))\n",
    "\n",
    "if not index_exists:\n",
    "    indexer = pt.IterDictIndexer(index_location)\n",
    "    index_ref = indexer.index(corpus_iter)\n",
    "    print(\"Indexing completed.\")\n",
    "else:\n",
    "    print(\"Index already exists, loading from disk.\")\n",
    "    index_ref = index_location"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T18:00:25.048953Z",
     "start_time": "2024-03-26T18:00:25.043704Z"
    }
   },
   "id": "7f344426c854e676"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 2: Retrieving Documents\n",
    "\n",
    "You need to use the created index to retrieve documents based on both the original and rewritten queries. You have already outlined this step correctly, but make sure that `index` is correctly initialized using the `index_ref` from the indexing step:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4929c9c9679a10c1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Assuming original_queries and rewritten_queries are your lists of queries\n",
    "query_ids = range(1, len(original_queries) + 1)  # Generating query IDs\n",
    "\n",
    "# Converting original queries to a DataFrame\n",
    "original_queries_df = pd.DataFrame({\n",
    "    'qid': query_ids,\n",
    "    'query': original_queries\n",
    "})\n",
    "\n",
    "# Converting rewritten queries to a DataFrame\n",
    "rewritten_queries_df = pd.DataFrame({\n",
    "    'qid': query_ids,\n",
    "    'query': rewritten_queries\n",
    "})"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d2a43b70db85b5f4"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "# Initialize index from the created index reference\n",
    "index = pt.IndexFactory.of(index_ref)\n",
    "\n",
    "# Retrieve documents for both original and rewritten queries using BM25\n",
    "original_res = pt.BatchRetrieve(index, wmodel=\"BM25\").transform(original_queries_df)\n",
    "rewritten_res = pt.BatchRetrieve(index, wmodel=\"BM25\").transform(rewritten_queries_df)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T18:00:47.807966Z",
     "start_time": "2024-03-26T18:00:25.050569Z"
    }
   },
   "id": "a2efe3df97d3ff87"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 3: Reranking the Results\n",
    "\n",
    "After retrieving the initial set of documents for both the original and rewritten queries, the next step is to rerank these results. You've outlined the process, assuming you have a `reranker` defined. This reranker could be any model or method that takes a set of retrieved documents and reorders them based on relevance. Let's proceed with the assumption:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "52572a40f2bada83"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reranker' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[30], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# TODO: implement reranking using the models\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m original_reranked \u001B[38;5;241m=\u001B[39m \u001B[43mreranker\u001B[49m\u001B[38;5;241m.\u001B[39mtransform(original_res)\n\u001B[1;32m      3\u001B[0m rewritten_reranked \u001B[38;5;241m=\u001B[39m reranker\u001B[38;5;241m.\u001B[39mtransform(rewritten_res)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'reranker' is not defined"
     ]
    }
   ],
   "source": [
    "# Example for loading one reranking file\n",
    "reranking_path = './model/doc_msmarco/doc_attention_2_davinci_final_3e-4.tsv'\n",
    "reranking_df = pd.read_csv(reranking_path, sep='\\t', header=None, names=['qid', 'docid', 'rank', 'score'])\n",
    "\n",
    "# Display the first few rows to understand its structure\n",
    "print(reranking_df.head())\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T18:00:47.822525Z",
     "start_time": "2024-03-26T18:00:47.814811Z"
    }
   },
   "id": "d24fedb90364fcb0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 4: Evaluating the Results\n",
    "\n",
    "Finally, to evaluate the effectiveness of the rewritten queries versus the original queries, you'll use PyTerrier's evaluation functionalities. You need to compare the reranked results against the relevance judgments (`qrels`) using various metrics:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aeb837633b6194f3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Evaluate both sets of reranked results using the same relevance judgments\n",
    "evaluator = pt.Evaluator()\n",
    "metrics = [\"map\", \"ndcg\", \"P_10\"]  # Example metrics: Mean Average Precision, nDCG, Precision at 10\n",
    "results = evaluator.evaluate([original_reranked, rewritten_reranked], qrels, metrics=metrics)\n",
    "\n",
    "print(results)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-26T18:00:47.820082Z"
    }
   },
   "id": "6d1c30176aea20aa"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-26T18:00:47.821830Z"
    }
   },
   "id": "7f78ca35567ede8d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
