{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T19:54:49.638280Z",
     "start_time": "2024-03-28T19:54:45.371687Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-terrier in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (0.10.0)\r\n",
      "Requirement already satisfied: numpy in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (1.26.4)\r\n",
      "Requirement already satisfied: pandas in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (2.2.0)\r\n",
      "Requirement already satisfied: wget in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (3.2)\r\n",
      "Requirement already satisfied: tqdm in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (4.65.0)\r\n",
      "Requirement already satisfied: pyjnius>=1.4.2 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (1.6.1)\r\n",
      "Requirement already satisfied: matchpy in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (0.5.5)\r\n",
      "Requirement already satisfied: scikit-learn in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (1.4.0)\r\n",
      "Requirement already satisfied: deprecated in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (1.2.14)\r\n",
      "Requirement already satisfied: chest in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (0.2.3)\r\n",
      "Requirement already satisfied: scipy in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (1.11.4)\r\n",
      "Requirement already satisfied: requests in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (2.31.0)\r\n",
      "Requirement already satisfied: joblib in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (1.3.2)\r\n",
      "Requirement already satisfied: nptyping==1.4.4 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (1.4.4)\r\n",
      "Requirement already satisfied: more-itertools in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (10.2.0)\r\n",
      "Requirement already satisfied: ir-datasets>=0.3.2 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (0.5.6)\r\n",
      "Requirement already satisfied: jinja2 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (3.1.3)\r\n",
      "Requirement already satisfied: statsmodels in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (0.14.1)\r\n",
      "Requirement already satisfied: ir-measures>=0.3.1 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (0.3.3)\r\n",
      "Requirement already satisfied: dill in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (0.3.8)\r\n",
      "Requirement already satisfied: pytrec-eval-terrier>=0.5.3 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from python-terrier) (0.5.6)\r\n",
      "Requirement already satisfied: typish>=1.7.0 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from nptyping==1.4.4->python-terrier) (1.9.3)\r\n",
      "Requirement already satisfied: beautifulsoup4>=4.4.1 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier) (4.12.2)\r\n",
      "Requirement already satisfied: inscriptis>=2.2.0 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier) (2.4.0.1)\r\n",
      "Requirement already satisfied: lxml>=4.5.2 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier) (5.1.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier) (6.0.1)\r\n",
      "Requirement already satisfied: trec-car-tools>=2.5.4 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier) (2.6)\r\n",
      "Requirement already satisfied: lz4>=3.1.10 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier) (4.3.3)\r\n",
      "Requirement already satisfied: warc3-wet>=0.2.3 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier) (0.2.3)\r\n",
      "Requirement already satisfied: warc3-wet-clueweb09>=0.2.5 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier) (0.2.5)\r\n",
      "Requirement already satisfied: zlib-state>=0.1.3 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier) (0.1.6)\r\n",
      "Requirement already satisfied: ijson>=3.1.3 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier) (3.2.3)\r\n",
      "Requirement already satisfied: pyautocorpus>=0.1.1 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier) (0.1.12)\r\n",
      "Requirement already satisfied: unlzw3>=0.2.1 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier) (0.2.2)\r\n",
      "Requirement already satisfied: cwl-eval>=1.0.10 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from ir-measures>=0.3.1->python-terrier) (1.0.12)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from requests->python-terrier) (2.0.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from requests->python-terrier) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from requests->python-terrier) (2.1.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from requests->python-terrier) (2024.2.2)\r\n",
      "Requirement already satisfied: heapdict in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from chest->python-terrier) (1.0.1)\r\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from deprecated->python-terrier) (1.14.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from jinja2->python-terrier) (2.1.3)\r\n",
      "Requirement already satisfied: multiset<3.0,>=2.0 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from matchpy->python-terrier) (2.1.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from pandas->python-terrier) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from pandas->python-terrier) (2023.3.post1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from pandas->python-terrier) (2024.1)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from scikit-learn->python-terrier) (3.3.0)\r\n",
      "Requirement already satisfied: patsy>=0.5.4 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from statsmodels->python-terrier) (0.5.6)\r\n",
      "Requirement already satisfied: packaging>=21.3 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from statsmodels->python-terrier) (23.1)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from beautifulsoup4>=4.4.1->ir-datasets>=0.3.2->python-terrier) (2.5)\r\n",
      "Requirement already satisfied: six in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from patsy>=0.5.4->statsmodels->python-terrier) (1.16.0)\r\n",
      "Requirement already satisfied: cbor>=1.0.0 in /Users/jasperbruin/anaconda3/envs/IR/lib/python3.10/site-packages (from trec-car-tools>=2.5.4->ir-datasets>=0.3.2->python-terrier) (1.0.0)\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTerrier 0.10.0 has loaded Terrier 5.8 (built by craigm on 2023-11-01 18:05) and terrier-helper 0.0.8\n",
      "\n",
      "No etc/terrier.properties, using terrier.default.properties for bootstrap configuration.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install python-terrier\n",
    "import pyterrier as pt\n",
    "if not pt.started():\n",
    "    pt.init()\n",
    "\n",
    "from transformers import BertModel\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from pyterrier.measures import RR, nDCG, MAP\n",
    "# Ensure NLTK data is downloaded only once\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beafbb0455e0ffc8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0b2ad49607e9ca7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T19:54:49.684162Z",
     "start_time": "2024-03-28T19:54:49.636014Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "msmarco-passage/trec-dl-2020 documents:   0%|          | 0/8841823 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# Example of loading a dataset from PyTerrier\n",
    "dataset = pt.get_dataset('irds:msmarco-passage/trec-dl-2020')\n",
    "\n",
    "topics = dataset.get_topics()\n",
    "qrels = dataset.get_qrels()\n",
    "corpus_iter = dataset.get_corpus_iter()\n",
    "# Convert to an iterator\n",
    "corpus_iterator = iter(corpus_iter)\n",
    "first_doc = next(corpus_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16535d9f9cb17283",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T19:54:49.690372Z",
     "start_time": "2024-03-28T19:54:49.684657Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1030303</td>\n",
       "      <td>who is aziz hashim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1037496</td>\n",
       "      <td>who is rep scalise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1043135</td>\n",
       "      <td>who killed nicholas ii of russia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1045109</td>\n",
       "      <td>who owns barnhart crane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1049519</td>\n",
       "      <td>who said no one can make you feel inferior</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       qid                                       query\n",
       "0  1030303                          who is aziz hashim\n",
       "1  1037496                          who is rep scalise\n",
       "2  1043135            who killed nicholas ii of russia\n",
       "3  1045109                     who owns barnhart crane\n",
       "4  1049519  who said no one can make you feel inferior"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d7b793eada6f871",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T19:54:49.696133Z",
     "start_time": "2024-03-28T19:54:49.692788Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>docno</th>\n",
       "      <th>label</th>\n",
       "      <th>iteration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23849</td>\n",
       "      <td>1020327</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23849</td>\n",
       "      <td>1034183</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23849</td>\n",
       "      <td>1120730</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23849</td>\n",
       "      <td>1139571</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23849</td>\n",
       "      <td>1143724</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     qid    docno  label iteration\n",
       "0  23849  1020327      2         0\n",
       "1  23849  1034183      3         0\n",
       "2  23849  1120730      0         0\n",
       "3  23849  1139571      1         0\n",
       "4  23849  1143724      0         0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qrels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9e1515d8868ea",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Load models\n",
    "\n",
    "This is loading the BertClassifier model, davinciContextModel and the DocQuery2DocModel model. The models are then loaded from the checkpoints and set to evaluation mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2d27d527d1cec7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T19:54:50.602209Z",
     "start_time": "2024-03-28T19:54:49.695884Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertClassifier(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (classification): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BertClassifier(nn.Module):\n",
    "    def __init__(self, num_labels=2):\n",
    "        super(BertClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        # Align the layer names with the checkpoint\n",
    "        self.classification = nn.Linear(768, num_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, token_type_ids=None):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        logits = self.classification(pooled_output)\n",
    "        return logits\n",
    "\n",
    "# Initialize the model\n",
    "classifier_model = BertClassifier()\n",
    "\n",
    "# Load the checkpoint\n",
    "model_path = './model/doc_baseline.ckpt'\n",
    "checkpoint = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "\n",
    "# Extract the state_dict, assuming the state dict is saved under 'state_dict'\n",
    "model_state_dict = checkpoint['state_dict']\n",
    "\n",
    "# Adjust keys in the state_dict as needed\n",
    "adjusted_model_state_dict = {}\n",
    "for key, value in model_state_dict.items():\n",
    "    # Remove the 'model.' prefix and handle the 'classifier' to 'classification' naming difference\n",
    "    new_key = key.replace('model.', '').replace('classification', 'classifier')\n",
    "    if 'position_ids' not in new_key:  # Ignore 'bert.embeddings.position_ids'\n",
    "        adjusted_model_state_dict[new_key] = value\n",
    "\n",
    "# Load the adjusted state dict\n",
    "classifier_model.load_state_dict(adjusted_model_state_dict, strict=False)\n",
    "classifier_model.eval()  # Set the model to evaluation mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cf48aca4b8b0c62",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T19:54:50.608781Z",
     "start_time": "2024-03-28T19:54:50.600837Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class TextPreprocessor:\n",
    "    def __init__(self):\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        self.stemmer = PorterStemmer()\n",
    "\n",
    "    def tokenize(self, text: str):\n",
    "        return word_tokenize(text)\n",
    "\n",
    "    def normalize(self, tokens):\n",
    "        return [re.sub(r'\\W+', '', token.lower()) for token in tokens if re.sub(r'\\W+', '', token.lower())]\n",
    "\n",
    "    def stopping(self, tokens):\n",
    "        return [token for token in tokens if token not in self.stop_words]\n",
    "\n",
    "    def stemming(self, tokens):\n",
    "        return [self.stemmer.stem(token) for token in tokens]\n",
    "\n",
    "    def preprocess(self, query: str, use_tokenize=True, use_normalize=True, use_stopping=True, use_stemming=False):\n",
    "        if query is None or not isinstance(query, str):\n",
    "            raise ValueError(\"Input query must be a non-empty string\")\n",
    "        tokens = self.tokenize(query) if use_tokenize else query.split()\n",
    "        if use_normalize: tokens = self.normalize(tokens)\n",
    "        if use_stopping: tokens = self.stopping(tokens)\n",
    "        if use_stemming: tokens = self.stemming(tokens)\n",
    "        return ' '.join(tokens)\n",
    "\n",
    "\n",
    "def preprocess_queries(query: str) -> str:\n",
    "    preprocessor = TextPreprocessor()\n",
    "    return preprocessor.preprocess(query, use_tokenize=True, use_normalize=True, use_stopping=True, use_stemming=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f73a7cb9837bb95",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Context-Aware Query Rewriting\n",
    "\n",
    "We need to adjust our logic here used the model from: https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f8769d96efb0d250",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T20:56:29.000167Z",
     "start_time": "2024-03-28T20:56:28.851440Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import re\n",
    "\n",
    "class ContextAwareQueryRewriter:\n",
    "    def __init__(self, classifier_model, inference_model_endpoint, tokenizer=None):\n",
    "        self.classifier_model = classifier_model\n",
    "        self.inference_model_endpoint = inference_model_endpoint\n",
    "        self.tokenizer = tokenizer if tokenizer else BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "\n",
    "    def needs_rewriting(self, query):\n",
    "            inputs = self.tokenizer(query, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "            with torch.no_grad():\n",
    "                output = self.classifier_model(**inputs)\n",
    "            logits = output.logits if hasattr(output, 'logits') else output\n",
    "            category = torch.argmax(F.log_softmax(logits, dim=1), dim=1).item()\n",
    "            return category == 1\n",
    "\n",
    "    def extract_context(self, query):\n",
    "        headers = {\"Authorization\": \"Bearer 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\"}\n",
    "        API_URL = \"https://api-inference.huggingface.co/models/ml6team/keyphrase-extraction-kbir-openkp\"\n",
    "        response = requests.post(API_URL, headers=headers, json={\"inputs\": query})\n",
    "    \n",
    "        if response.status_code == 200:\n",
    "            keyphrases = response.json()\n",
    "    \n",
    "            # Create a context string by joining the 'word' values from each keyphrase.\n",
    "            extracted_context = ', '.join([kp['word'].strip() for kp in keyphrases])\n",
    "    \n",
    "            return extracted_context\n",
    "        else:\n",
    "            print(\"Error: Unable to extract context.\")\n",
    "            return None\n",
    "\n",
    "\n",
    "    def rewrite_query(self, query):\n",
    "        \"\"\"\n",
    "        Rewriting Phase: Rewrite the given query based on the provided context using model inference.\n",
    "        \n",
    "        :param query: The original search query.\n",
    "        :param context: Context or background information relevant to the query.\n",
    "        :return: A rewritten query that better captures the intent, considering the context.\n",
    "        \"\"\"\n",
    "        # Construct a prompt that is clearly demarcated to help separate the response from the prompt.\n",
    "        context = self.extract_context(query)\n",
    "        if not context:\n",
    "            context = \"[Context not available]\"\n",
    "        prompt = f\"Rewrite the following into a precise query for information retrieval based on the context '{context}': '{query}'. Provide only the query.\"\n",
    "        payload = {\"inputs\": prompt}\n",
    "        response = self.query_model(payload)\n",
    "        if response and \"generated_text\" in response[0]:\n",
    "            rewritten_query = response[0][\"generated_text\"].split(prompt)[-1].strip()\n",
    "            return rewritten_query\n",
    "        else:\n",
    "            return query\n",
    "\n",
    "\n",
    "    def query_model(self, payload):\n",
    "        headers = {\"Authorization\": \"Bearer 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\"}\n",
    "        response = requests.post(self.inference_model_endpoint, headers=headers, json=payload)\n",
    "        return response.json()\n",
    "\n",
    "    def transform(self, queries):\n",
    "        rewritten_queries = []\n",
    "        for query in queries:\n",
    "            # First, check if the query needs rewriting\n",
    "            if self.needs_rewriting(query):\n",
    "                # If it does, rewrite the query based on extracted context\n",
    "                rewritten_query = self.rewrite_query(query)\n",
    "                rewritten_queries.append(rewritten_query if rewritten_query else query)\n",
    "            else:\n",
    "                # If it doesn't need rewriting, add it as is\n",
    "                rewritten_queries.append(query)\n",
    "        return rewritten_queries\n",
    "\n",
    "\n",
    "# Initialize ContextAwareQueryRewriter\n",
    "classifier_model = classifier_model\n",
    "inference_model_endpoint = \"https://api-inference.huggingface.co/models/mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "query_rewriter = ContextAwareQueryRewriter(classifier_model, inference_model_endpoint, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4d2669453333623a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T20:57:47.940160Z",
     "start_time": "2024-03-28T20:57:47.458598Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'score': 0.1272163987159729, 'token': 7954, 'token_str': 'meal', 'sequence': 'the main ingredient in a quiche meal is'}, {'score': 0.09382666647434235, 'token': 9850, 'token_str': 'cake', 'sequence': 'the main ingredient in a quiche cake is'}, {'score': 0.07288110256195068, 'token': 11350, 'token_str': 'soup', 'sequence': 'the main ingredient in a quiche soup is'}, {'score': 0.05692329257726669, 'token': 12901, 'token_str': 'sauce', 'sequence': 'the main ingredient in a quiche sauce is'}, {'score': 0.04582372307777405, 'token': 11642, 'token_str': 'sandwich', 'sequence': 'the main ingredient in a quiche sandwich is'}]\n"
     ]
    }
   ],
   "source": [
    "context = \"In the context of French cuisine\"\n",
    "original_query = \"The main ingredient in a quiche [MASK] is\"\n",
    "refined_query = query_rewriter.fill_in_the_mask(original_query)\n",
    "\n",
    "print(refined_query)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfaf86fc74814ce",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Step 1: Extracting Original Queries\n",
    "\n",
    "You've already loaded the dataset and accessed the topics, which contain the queries. The code snippet you've shown extracts the queries from the `topics` DataFrame provided by PyTerrier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b433065d9872a592",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-29T07:32:55.306715Z",
     "start_time": "2024-03-29T07:32:29.702618Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['who is aziz hashim', 'who is rep scalise', 'who killed nicholas ii of russia', 'who owns barnhart crane', 'who said no one can make you feel inferior', 'who sings monk theme song', 'who was the highest career passer rating in the nfl', 'why do hunters pattern their shotguns', 'why do some places on my scalp feel sore', 'why is pete rose banned from hall of fame', 'who is thomas m cooley', 'definition of endorsing', 'which hormone increases calcium levels in the blood', 'define geon', 'where can the amazon rainforest is located', 'when are the four forces that act on an airplane in equilibrium', 'define pareto chart in statistics', 'what year were the timberwolves founded', 'what year did knee deep come out funkadelic', 'define define gallows', 'what tissue composes the hypodermis', 'what time zone is st paul minnesota in', 'what the best way to get clothes white', 'what temperature and humidity to dry sausage', 'what mental illnesses', 'what medium do radio waves travel through', 'what language is craith filmed in', 'what is the un fao', 'what is the distance between flat rock michigan and detroit michigan', 'what is shakespeare s theatre called', 'what is reba mcentire s net worth', 'what is it called when your blood becomes too thin', 'what is in the meat group', 'conformative definition', 'what is chaff and flare', 'what is a nonconformity earth science', 'what does unauthorized act in writing mean', 'what does the word pottery mean', 'what does provisions mean', 'what does plank owner mean', 'what does distraint mean', 'what does a psychological screening consist of for egg donors', 'caries detection system', 'what can you do about discrimination in the workplace in oklahoma city', 'what are the major political parties in great britain select all that apply', 'what are symptoms of kid', 'what amino produces carnitine', 'what adobe do you need to create external links in a pdf document', 'walmart phone number linton in', 'briefly describe how the lungs function', 'routing number for savings bank of maine', 'reigning definition', 'outmaneuver definition', 'number of employees for disa global solutions', 'ms symptoms ms', 'monk meaning', 'meaning of shebang', 'is the medicine toradol a narcotic', 'in healthcare what does iihi stand for', 'how much do a passport', 'how much cornstarch is needed to thicken', 'how many years you have to go through and school is to become a anesthesiologist', 'how many sons robert kraft has', 'how many bricks per wall', 'how long to cook potato wedges in the oven from frozen', 'average annual income data analyst', 'how long do you stay contagious with the flu', 'how long do i cook artichokes for', 'how long do hormonal headaches last', 'how does vitamin c helps', 'how does granulation tissue start', 'hotshot members', 'holidays definition', 'head basketball coach at texas a m', 'geneva il median sales price', 'flyover definition', 'first eagle credit union routing number', 'antibiotics for what kind of infection', 'embedded payments definition', 'dx code for thoracic outlet syndrome', 'does low vitamin cause tingling', 'difference between a hotel and motel', 'difference between a company s strategy and business model is', 'why does lacquered brass tarnish', 'why did the ancient egyptians call their land kemet or black land', 'define bmt medical', 'define curvilinear', 'define etruscans', 'define premature babies', 'definition of laudable', 'describe how muscles and bones work together to produce movement', 'did prohibition increased crime', 'do google docs auto save', 'does ethambutol treat bone infection', 'does mississippi have an income tax', 'dog day afternoon meaning', 'driving distance geneva ny to syracuse', 'eating foods that are considered warm', 'estar meaning', 'group edit policy']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc3b43bca21a4b72aba1ec7de90c9e00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/312 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f5b3385b11e450eafa5793ef4f4f085",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/740 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b84399ba2cc4e1b826951000db87de7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52b091ccc9cd404cbf687bced552a76b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0041969d4d043f3afe6c807397121cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fa3e7fa39d04581a1856625ed32d824",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/501M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Ashishkr/query_wellformedness_score were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9743],\n",
      "        [0.1841],\n",
      "        [0.6934],\n",
      "        [0.6095],\n",
      "        [0.7336],\n",
      "        [0.3793],\n",
      "        [0.6265],\n",
      "        [0.9032],\n",
      "        [0.8124],\n",
      "        [0.6394],\n",
      "        [0.6664],\n",
      "        [0.2150],\n",
      "        [1.0061],\n",
      "        [0.2947],\n",
      "        [0.1853],\n",
      "        [0.7173],\n",
      "        [0.1922],\n",
      "        [0.9775],\n",
      "        [0.7670],\n",
      "        [0.1133],\n",
      "        [0.6861],\n",
      "        [0.7636],\n",
      "        [0.1986],\n",
      "        [0.1304],\n",
      "        [0.0420],\n",
      "        [1.0067],\n",
      "        [0.6026],\n",
      "        [0.2620],\n",
      "        [0.7683],\n",
      "        [0.2335],\n",
      "        [0.3470],\n",
      "        [0.8602],\n",
      "        [0.9789],\n",
      "        [0.1109],\n",
      "        [0.5709],\n",
      "        [0.4360],\n",
      "        [0.7824],\n",
      "        [0.9976],\n",
      "        [0.2031],\n",
      "        [0.6526],\n",
      "        [0.9268],\n",
      "        [0.9725],\n",
      "        [0.1249],\n",
      "        [0.7022],\n",
      "        [0.0669],\n",
      "        [0.1188],\n",
      "        [0.5852],\n",
      "        [0.6538],\n",
      "        [0.0332],\n",
      "        [0.4317],\n",
      "        [0.2625],\n",
      "        [0.0872],\n",
      "        [0.1248],\n",
      "        [0.2465],\n",
      "        [0.0930],\n",
      "        [0.0352],\n",
      "        [0.2113],\n",
      "        [0.9459],\n",
      "        [0.7976],\n",
      "        [0.0205],\n",
      "        [0.8214],\n",
      "        [0.0910],\n",
      "        [0.0098],\n",
      "        [0.0892],\n",
      "        [0.6675],\n",
      "        [0.0661],\n",
      "        [0.9982],\n",
      "        [0.9708],\n",
      "        [0.9899],\n",
      "        [0.0552],\n",
      "        [0.5496],\n",
      "        [0.0592],\n",
      "        [0.1131],\n",
      "        [0.2657],\n",
      "        [0.0612],\n",
      "        [0.0811],\n",
      "        [0.1303],\n",
      "        [0.1402],\n",
      "        [0.1892],\n",
      "        [0.2999],\n",
      "        [0.4747],\n",
      "        [0.5433],\n",
      "        [0.2516],\n",
      "        [0.9323],\n",
      "        [0.5877],\n",
      "        [0.2025],\n",
      "        [0.2134],\n",
      "        [0.2567],\n",
      "        [0.1978],\n",
      "        [0.1498],\n",
      "        [0.5568],\n",
      "        [0.1189],\n",
      "        [0.9024],\n",
      "        [0.9736],\n",
      "        [0.9486],\n",
      "        [0.0529],\n",
      "        [0.0982],\n",
      "        [0.3353],\n",
      "        [0.0661],\n",
      "        [0.0392]])\n"
     ]
    }
   ],
   "source": [
    "# Assuming you've already loaded the dataset and have the 'topics' DataFrame\n",
    "original_queries = [topic['query'] for topic_id, topic in topics.iterrows()]\n",
    "\n",
    "print(original_queries[:100])\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Ashishkr/query_wellformedness_score\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"Ashishkr/query_wellformedness_score\")\n",
    "sentences = original_queries[:100]\n",
    "features = tokenizer(sentences, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    scores = model(**features).logits\n",
    "print(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c92803a34bad326",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-29T07:37:14.203966Z",
     "start_time": "2024-03-29T07:37:14.196549Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queries to Rewrite: []\n"
     ]
    }
   ],
   "source": [
    "# Assume scores is a tensor of shape (num_queries, num_classes) and you're interested in the score for being well-formed\n",
    "well_formed_scores = torch.sigmoid(scores)[:, 0]  # Apply sigmoid if the scores are logits\n",
    "\n",
    "# Set a threshold for selecting queries that need to be rewritten\n",
    "threshold = 0.5\n",
    "\n",
    "# Select queries with scores below the threshold\n",
    "queries_to_rewrite = [query for query, score in zip(original_queries[:100], well_formed_scores) if score < threshold]\n",
    "\n",
    "print(\"Queries to Rewrite:\", queries_to_rewrite)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12b3fedf7450124a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T20:33:35.964594Z",
     "start_time": "2024-03-28T20:31:47.992236Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['who is aziz hashim', 'who is rep scalise', 'who killed nicholas ii of russia', 'who owns barnhart crane', \"``Who spoke the phrase 'no one can make you feel inferior'?'''\\n\\nNote: For information retrieval queries, it's essential to be as specific and clear as possible to ensure accurate results. In this case, we're looking for the identities of individuals who have made the statement, so our query focuses on the speaker(s) and the exact phrase.\", 'who sings monk theme song', 'who was the highest career passer rating in the nfl', 'why do hunters pattern their shotguns', '```\\nwhy do certain areas on my scalp present with tenderness or discomfort?', 'why is pete rose banned from hall of fame', \"query: thomas m cooley author\\n\\nThis query assumes a library catalog or information database context, reflecting that 'Thomas M. Cooley' is most likely an author or a topic of a published work.\", 'definition of endorsing', 'which hormone increases calcium levels in the blood', 'define geon', 'LOCATE \"amazon rainforest\" IN [DATABASE/COLLECTION]\\nRETURN [FIELD_WITH_LOCATION_INFO]\\nFROM [DATA_TYPE]\\nWHERE [FIELD_WITH_LOCATION_INFO] IS NOT NULL;', 'when are the four forces that act on an airplane in equilibrium', 'define pareto chart in statistics', 'what year were the timberwolves founded', 'what year did knee deep come out funkadelic', 'query: define gallows meaning', 'what tissue composes the hypodermis', 'what time zone is st paul minnesota in', \"```SQL\\nSELECT recommendations\\nFROM cleaning_tips\\nWHERE context = 'clothes white' AND type = 'cleaning'\\nORDER BY relevance DESC\\nLIMIT 1;\\n```\\n\\nIn this query, we are looking for recommendations related to cleaning clothes that are white from a table named `cleaning_tips`. We filter the data based on the context 'clothes white' and the type 'cleaning'. The results are ordered by\", 'Query: Retrieve information regarding the optimal temperature and humidity levels for drying sausage.', 'what mental illnesses', 'what medium do radio waves travel through', 'what language is craith filmed in', 'what is the un fao', 'what is the distance between flat rock michigan and detroit michigan', 'what is shakespeare s theatre called', 'what is reba mcentire s net worth', '\"blood thinning condition name\"\\n\\nThis query uses specific keywords related to the context and focuses on retrieving information about the name of a condition that results in thin blood.', 'what is in the meat group', 'conformative definition', 'what is chaff and flare', 'what is a nonconformity earth science', \"```sql\\nSELECT description\\nFROM TermDefinitionTable\\nWHERE term = 'unauthorized act' AND context = 'writing';\\n```\", \"How do I find information about the meaning of the word 'pottery'? Exact query: Define: pottery.\", '\"Define the meaning of the term \\'provisions\\'.\"\\n\\nOR:\\n\\n\"What is the definition of \\'provisions\\'?\"\\n\\nOR:\\n\\n\"Meaning of \\'provisions\\': retrieve a definition.\"', 'QUERY: Define meaning of term \"plank owner\" in maritime context.', 'query: define:distraint', 'Query: \"Describe the components of a psychological screening process for egg donor applicants.\"', 'QUERY: Retrieve information on systems designed specifically for the purpose of detecting dental caries.', 'what can you do about discrimination in the workplace in oklahoma city', 'what are the major political parties in great britain select all that apply', 'what are symptoms of kid', 'what amino produces carnitine', 'what adobe do you need to create external links in a pdf document', '```vbnet\\n\"Find the phone number for Walmart located in Linton.\"\\n\\nSELECT phone_number\\nFROM store_data\\nWHERE store_name = \\'Walmart\\'\\nAND location = \\'Linton\\';', 'briefly describe how the lungs function', 'routing number for savings bank of maine', 'Query: Define reigning.', 'outmaneuver definition', 'number of employees for disa global solutions', 'ms symptoms ms', 'monk meaning', \"```sql\\nSELECT description\\nFROM KnowledgeBase\\nWHERE term = 'shebang'\\n```\\n\\nThis query assumes there is a table named 'KnowledgeBase' with a column named 'description' and a column named 'term'. The query will return the description related to the term 'shebang' from the 'KnowledgeBase' table.\", 'is the medicine toradol a narcotic', 'in healthcare what does iihi stand for', 'What is the cost of obtaining a new passport?', '```queries:\\n[{\"query\": \"What amount of cornstarch is required to thicken a given quantity of liquid?\"}]\\n```\\n\\nThis query aims to retrieve information on the specific amount of cornstarch needed to thicken a certain quantity of liquid.', 'how many years you have to go through and school is to become a anesthesiologist', 'how many sons robert kraft has', '```query\\nAverage number of bricks per unit length of wall\\n```\\n\\nOr if the context is explicit about the wall being made of bricks, maybe:\\n\\n```query\\nNumber of bricks per linear foot (or meter) of wall\\n```', 'Query: \"What is the baking duration for potato wedges in an oven when they are frozen?\"', 'average annual income data analyst', 'how long do you stay contagious with the flu', '```\\nWhat is the cooking duration for artichokes?\\n```\\n\\n```\\nquery: cooking duration artichokes\\n```\\n\\nor\\n\\n```\\nquery: how long to cook artichokes\\n```\\n\\nor\\n\\n```\\nquery: artichoke cooking time\\n```\\n\\nThese queries should return information specifically related to the cooking time or duration for artichokes.', 'Query: Retrieve documents containing information on the duration of hormonal headaches.', 'QUERY: What are the health benefits or functions of Vitamin C?', '\"Retrieve information on the process of granulation tissue formation.\"\\n\\nQUERY: \"granulation tissue formation process\"\\nOR: \"how does granulation tissue develop\"\\nOR: \"what causes granulation tissue to grow\"\\nOR: \"granulation tissue genesis\"\\nOR: \"mechanisms of granulation tissue generation\"', 'hotshot members', 'holidays definition', 'head basketball coach at texas a m', 'geneva il median sales price', 'QUERY: \"What is the definition of a flyover?\"', 'first eagle credit union routing number', 'antibiotics for what kind of infection', '```query:\\ndefine:embedded payments\\n```\\n\\nOr if you prefer a more explicit search query:\\n\\n```query:\\ndefinition embedded payments\\n```\\n\\nBoth of these queries should return definitions or explanations of what embedded payments are.', 'dx code for thoracic outlet syndrome', 'QUERY: Does a deficiency in specific vitamins result in the sensation of tingling?', 'difference between a hotel and motel', 'difference between a company s strategy and business model is', 'Why does lacquered brass tarnish? (Information retrieval query)', 'why did the ancient egyptians call their land kemet or black land', 'define bmt medical', '```\\ndefine: curvilinear coord: system shape: curvilinear\\n```\\n\\nThis query would be used in a context where a precise definition and information about curvilinear coordinate systems is being sought.', 'define etruscans', 'define premature babies', \"SELECT * FROM definitions\\nWHERE term = 'laudable' AND category = 'definition';\", 'describe how muscles and bones work together to produce movement', 'did prohibition increased crime', 'do google docs auto save', 'does ethambutol treat bone infection', 'does mississippi have an income tax', 'dog day afternoon meaning', 'driving distance geneva ny to syracuse', 'eating foods that are considered warm', 'estar meaning', 'group edit policy']\n"
     ]
    }
   ],
   "source": [
    "# rewrite the 50 queries\n",
    "rewritten_queries = query_rewriter.transform(original_queries[:100])\n",
    "\n",
    "print(rewritten_queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d5311335373f64",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Step 2: Rewriting Queries\n",
    "\n",
    "You've also created a `QueryRewriter` class that takes in a model and a tokenizer to rewrite queries based on a certain logic (in your case, this logic depends on the predictions from a BertClassifier model). Initialize the `QueryRewriter` with the necessary model and tokenizer, and then use it to rewrite the preprocessed queries:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720525af9081cece",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Step 3: Preprocessing Queries (Optional)\n",
    "\n",
    "You've defined a `TextPreprocessor` class for preprocessing queries. You can apply this preprocessing to each of the original queries to get them ready for the rewriting process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f27a036be565b2",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-28T19:56:55.253874Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# preprocessor = TextPreprocessor()\n",
    "# preprocessed_queries = [preprocessor.preprocess(query) for query in original_queries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5dc4f5b256ac445",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T19:56:55.256611Z",
     "start_time": "2024-03-28T19:56:55.255714Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Rewritten queries: \")\n",
    "print(rewritten_queries[:10])\n",
    "print(\"\\nOriginal queries: \")\n",
    "print(original_queries[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d73d15c5c715dc",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Evaluating Rewritten vs. Original Queries with Doc MSMARCO Reranked Models\n",
    "\n",
    "### Objective\n",
    "\n",
    "The goal is to utilize the four doc_msmarco reranked models to compare the performance of rewritten queries against original queries.\n",
    "\n",
    "### Location of Reranked Models\n",
    "\n",
    "The reranked models are stored within the `doc_msmarco` directory, under the `model` folder. Here's the structure:\n",
    "\n",
    "```\n",
    "model/\n",
    " doc_baseline.ckpt\n",
    " doc_davinci_doc_context.ckpt\n",
    " wetransfer_model-1-doc2query-all-rankers_2024-03-21_1327/\n",
    "     best_rank_list/\n",
    "        doc_msmarco/\n",
    "            doc_attention_2_davinci_final_3e-4.tsv\n",
    "            doc_davinci03_doc_context_400tok_5e-4.tsv\n",
    "            doc_linear_2_davinci_final_1e-4.tsv\n",
    "            doc_query_2_doc_3e-4.tsv\n",
    "     doc_query2doc.ckpt\n",
    "```\n",
    "\n",
    "### Procedure\n",
    "\n",
    "1. **Retrieve Documents**: Initially, documents are fetched from the MS MARCO datasets for the purpose of reranking.\n",
    "\n",
    "2. **Reranking**: Utilize the retrieved documents along with the queries (both original and rewritten) to perform reranking using the models specified above.\n",
    "\n",
    "3. **Evaluation**: Assess the reranking process to determine the effectiveness of rewritten queries in comparison to the original ones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7454fc2217c8bf8f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Step 1: Indexing the Corpus\n",
    "\n",
    "Before we can retrieve and rerank documents based on queries, we need to ensure that the documents are indexed. You've mentioned creating an index but commented out the relevant code. Here's how you can do it properly with Pyterrier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc6b1fc0be71c91",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f344426c854e676",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T19:56:55.257610Z",
     "start_time": "2024-03-28T19:56:55.256820Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "index_location = str(Path(\"index\").absolute())\n",
    "index_exists = os.path.isfile(os.path.join(index_location, \"data.properties\"))\n",
    "\n",
    "if not index_exists:\n",
    "    indexer = pt.IterDictIndexer(index_location)\n",
    "    index_ref = indexer.index(corpus_iter)\n",
    "    print(\"Indexing completed.\")\n",
    "else:\n",
    "    print(\"Index already exists, loading from disk.\")\n",
    "    index_ref = index_location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4929c9c9679a10c1",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Step 2: Retrieving Documents\n",
    "\n",
    "You need to use the created index to retrieve documents based on both the original and rewritten queries. You have already outlined this step correctly, but make sure that `index` is correctly initialized using the `index_ref` from the indexing step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a43b70db85b5f4",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-28T19:56:55.258413Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Assuming original_queries and rewritten_queries are your lists of queries\n",
    "query_ids = range(1, len(original_queries) + 1)  # Generating query IDs\n",
    "\n",
    "# Converting original queries to a DataFrame\n",
    "original_queries_df = pd.DataFrame({\n",
    "    'qid': query_ids,\n",
    "    'query': original_queries\n",
    "})\n",
    "\n",
    "# Converting rewritten queries to a DataFrame\n",
    "rewritten_queries_df = pd.DataFrame({\n",
    "    'qid': query_ids,\n",
    "    'query': rewritten_queries\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2efe3df97d3ff87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T19:56:55.259460Z",
     "start_time": "2024-03-28T19:56:55.258685Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize index from the created index reference\n",
    "index = pt.IndexFactory.of(index_ref)\n",
    "\n",
    "# Retrieve documents for both original and rewritten queries using BM25\n",
    "original_res = pt.BatchRetrieve(index, wmodel=\"BM25\").transform(original_queries_df)\n",
    "rewritten_res = pt.BatchRetrieve(index, wmodel=\"BM25\").transform(rewritten_queries_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb837633b6194f3",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Step 4: Evaluating the Results\n",
    "\n",
    "Finally, to evaluate the effectiveness of the rewritten queries versus the original queries, you'll use PyTerrier's evaluation functionalities. You need to compare the reranked results against the relevance judgments (`qrels`) using various metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1c30176aea20aa",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-28T19:56:55.259412Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyterrier.measures import RR, nDCG, AP\n",
    "\n",
    "# Ensure your reranked DataFrames are named appropriately and structured correctly\n",
    "# They should have columns ['qid', 'docno', 'score']\n",
    "\n",
    "# Perform the evaluation using PyTerrier's Experiment function\n",
    "# results = pt.Experiment(\n",
    "#     [original_res_sorted, rewritten_res_sorted],\n",
    "#     topics,  # Your original queries DataFrame\n",
    "#     qrels,  # The qrels DataFrame with relevance judgments\n",
    "#     eval_metrics=[nDCG@10, AP(rel=10), RR(rel=10), nDCG@20],\n",
    "#     names=[\"Original Reranked\", \"Rewritten Reranked\"],\n",
    "#     baseline=0,  # Optionally specify which result set is considered the 'baseline' for comparison\n",
    "# )\n",
    "\n",
    "# Display the evaluation result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
